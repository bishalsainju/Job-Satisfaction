{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Job_Status</th>\n",
       "      <th>Reviewed_Year</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Px_Texts</th>\n",
       "      <th>Tknz_Texts</th>\n",
       "      <th>Doc_Length</th>\n",
       "      <th>Work_Life</th>\n",
       "      <th>Benefits</th>\n",
       "      <th>Job_Advancement</th>\n",
       "      <th>Management</th>\n",
       "      <th>Culture</th>\n",
       "      <th>Company_Index</th>\n",
       "      <th>Company_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>hour lunch, friendly co-workers.</td>\n",
       "      <td>cowork friendli hour lunch friendli_cowork hou...</td>\n",
       "      <td>['cowork', 'friendli', 'hour', 'lunch', 'frien...</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>benefits, Medical, dental, myshare, 401k, stocks</td>\n",
       "      <td>benefit dental medic myshar stock</td>\n",
       "      <td>['benefit', 'dental', 'medic', 'myshar', 'stock']</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>discount card . schedule 3 on 3 off</td>\n",
       "      <td>card discount schedul discount_card</td>\n",
       "      <td>['card', 'discount', 'schedul', 'discount_card']</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>good break lengths and plenty of hours</td>\n",
       "      <td>break hour length plenti plenti_hour</td>\n",
       "      <td>['break', 'hour', 'length', 'plenti', 'plenti_...</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>My pay was good and my schedule allowed me to ...</td>\n",
       "      <td>allow job pay schedul pay_schedul</td>\n",
       "      <td>['allow', 'job', 'pay', 'schedul', 'pay_schedul']</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Ratings  Job_Status  Reviewed_Year  \\\n",
       "0           0      2.0           1           2017   \n",
       "1           1      3.0           1           2015   \n",
       "2           2      2.0           0           2012   \n",
       "3           3      4.0           0           2017   \n",
       "4           4      1.0           1           2016   \n",
       "\n",
       "                                         Review_Text  \\\n",
       "0                   hour lunch, friendly co-workers.   \n",
       "1   benefits, Medical, dental, myshare, 401k, stocks   \n",
       "2                discount card . schedule 3 on 3 off   \n",
       "3             good break lengths and plenty of hours   \n",
       "4  My pay was good and my schedule allowed me to ...   \n",
       "\n",
       "                                            Px_Texts  \\\n",
       "0  cowork friendli hour lunch friendli_cowork hou...   \n",
       "1                benefit dental medic myshar stock     \n",
       "2               card discount schedul discount_card    \n",
       "3              break hour length plenti plenti_hour    \n",
       "4                 allow job pay schedul pay_schedul    \n",
       "\n",
       "                                          Tknz_Texts  Doc_Length  Work_Life  \\\n",
       "0  ['cowork', 'friendli', 'hour', 'lunch', 'frien...           9        3.0   \n",
       "1  ['benefit', 'dental', 'medic', 'myshar', 'stock']           5        3.0   \n",
       "2   ['card', 'discount', 'schedul', 'discount_card']           4        1.0   \n",
       "3  ['break', 'hour', 'length', 'plenti', 'plenti_...           5        4.0   \n",
       "4  ['allow', 'job', 'pay', 'schedul', 'pay_schedul']           5        3.0   \n",
       "\n",
       "   Benefits  Job_Advancement  Management  Culture  Company_Index Company_Name  \n",
       "0       2.0              2.0         1.0      3.0              1      Walmart  \n",
       "1       4.0              4.0         3.0      3.0              1      Walmart  \n",
       "2       4.0              3.0         1.0      3.0              1      Walmart  \n",
       "3       3.0              3.0         4.0      4.0              1      Walmart  \n",
       "4       3.0              1.0         1.0      1.0              1      Walmart  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(33624, 15)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import gensim \n",
    "from gensim import corpora, models, similarities\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"~/Desktop/R_js/data/pro_doc_sampled.csv\")\n",
    "display(df.head())\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hour lunch, friendly co-workers.', 'benefits, Medical, dental, myshare, 401k, stocks', 'discount card . schedule 3 on 3 off', 'good break lengths and plenty of hours', 'My pay was good and my schedule allowed me to work my other jobs']\n"
     ]
    }
   ],
   "source": [
    "reviews = df.Review_Text.tolist()\n",
    "print(reviews[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holy graill aeroplane\n"
     ]
    }
   ],
   "source": [
    "# Data Clean\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "# stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "stop_words.append(\"myshare\")\n",
    "\n",
    "def remove_url(text):\n",
    "    return re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', '', text)\n",
    "\n",
    "\n",
    "def remove_at(text):\n",
    "    return re.sub('@[^\\s]+', '', text)\n",
    "\n",
    "\n",
    "def remove_hash(text):\n",
    "    return text.replace(\"#\", \"\")\n",
    "\n",
    "\n",
    "def remove_punct(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "\n",
    "def remove_letter_repitition(text):\n",
    "    return re.sub(r'\\d+','', text)\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1\\1', text)\n",
    "\n",
    "def remove_stopwords(text): \n",
    "    return \" \".join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "def remove_alphabets(text):\n",
    "    return ' '.join( [w for w in input.split() if len(w)>1] )\n",
    "\n",
    "\n",
    "\n",
    "def clean_data(text):\n",
    "    text = text.lower()\n",
    "    text = remove_url(text)\n",
    "    text = remove_at(text)\n",
    "    text = remove_hash(text)\n",
    "    text = remove_punct(text)\n",
    "    text = remove_letter_repitition(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(clean_data(\"What the !! up holy graill aeroplane a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hour', 'lunch', 'friendly', 'coworkers'], ['benefits', 'medical', 'dental', 'k', 'stocks'], ['discount', 'card', 'schedule'], ['good', 'break', 'lengths', 'plenty', 'hours'], ['pay', 'good', 'schedule', 'allowed', 'work', 'jobs']]\n"
     ]
    }
   ],
   "source": [
    "tok_reviews = [nltk.word_tokenize(clean_data(review)) for review in reviews]\n",
    "print(tok_reviews[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tknz_Texts1'] = tok_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Job_Status</th>\n",
       "      <th>Reviewed_Year</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Px_Texts</th>\n",
       "      <th>Tknz_Texts</th>\n",
       "      <th>Doc_Length</th>\n",
       "      <th>Work_Life</th>\n",
       "      <th>Benefits</th>\n",
       "      <th>Job_Advancement</th>\n",
       "      <th>Management</th>\n",
       "      <th>Culture</th>\n",
       "      <th>Company_Index</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Tknz_Texts1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>hour lunch, friendly co-workers.</td>\n",
       "      <td>cowork friendli hour lunch friendli_cowork hou...</td>\n",
       "      <td>['cowork', 'friendli', 'hour', 'lunch', 'frien...</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>[hour, lunch, friendly, coworkers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>benefits, Medical, dental, myshare, 401k, stocks</td>\n",
       "      <td>benefit dental medic myshar stock</td>\n",
       "      <td>['benefit', 'dental', 'medic', 'myshar', 'stock']</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>[benefits, medical, dental, k, stocks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>discount card . schedule 3 on 3 off</td>\n",
       "      <td>card discount schedul discount_card</td>\n",
       "      <td>['card', 'discount', 'schedul', 'discount_card']</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>[discount, card, schedule]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>good break lengths and plenty of hours</td>\n",
       "      <td>break hour length plenti plenti_hour</td>\n",
       "      <td>['break', 'hour', 'length', 'plenti', 'plenti_...</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>[good, break, lengths, plenty, hours]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>My pay was good and my schedule allowed me to ...</td>\n",
       "      <td>allow job pay schedul pay_schedul</td>\n",
       "      <td>['allow', 'job', 'pay', 'schedul', 'pay_schedul']</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>[pay, good, schedule, allowed, work, jobs]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Ratings  Job_Status  Reviewed_Year  \\\n",
       "0           0      2.0           1           2017   \n",
       "1           1      3.0           1           2015   \n",
       "2           2      2.0           0           2012   \n",
       "3           3      4.0           0           2017   \n",
       "4           4      1.0           1           2016   \n",
       "\n",
       "                                         Review_Text  \\\n",
       "0                   hour lunch, friendly co-workers.   \n",
       "1   benefits, Medical, dental, myshare, 401k, stocks   \n",
       "2                discount card . schedule 3 on 3 off   \n",
       "3             good break lengths and plenty of hours   \n",
       "4  My pay was good and my schedule allowed me to ...   \n",
       "\n",
       "                                            Px_Texts  \\\n",
       "0  cowork friendli hour lunch friendli_cowork hou...   \n",
       "1                benefit dental medic myshar stock     \n",
       "2               card discount schedul discount_card    \n",
       "3              break hour length plenti plenti_hour    \n",
       "4                 allow job pay schedul pay_schedul    \n",
       "\n",
       "                                          Tknz_Texts  Doc_Length  Work_Life  \\\n",
       "0  ['cowork', 'friendli', 'hour', 'lunch', 'frien...           9        3.0   \n",
       "1  ['benefit', 'dental', 'medic', 'myshar', 'stock']           5        3.0   \n",
       "2   ['card', 'discount', 'schedul', 'discount_card']           4        1.0   \n",
       "3  ['break', 'hour', 'length', 'plenti', 'plenti_...           5        4.0   \n",
       "4  ['allow', 'job', 'pay', 'schedul', 'pay_schedul']           5        3.0   \n",
       "\n",
       "   Benefits  Job_Advancement  Management  Culture  Company_Index Company_Name  \\\n",
       "0       2.0              2.0         1.0      3.0              1      Walmart   \n",
       "1       4.0              4.0         3.0      3.0              1      Walmart   \n",
       "2       4.0              3.0         1.0      3.0              1      Walmart   \n",
       "3       3.0              3.0         4.0      4.0              1      Walmart   \n",
       "4       3.0              1.0         1.0      1.0              1      Walmart   \n",
       "\n",
       "                                  Tknz_Texts1  \n",
       "0          [hour, lunch, friendly, coworkers]  \n",
       "1      [benefits, medical, dental, k, stocks]  \n",
       "2                  [discount, card, schedule]  \n",
       "3       [good, break, lengths, plenty, hours]  \n",
       "4  [pay, good, schedule, allowed, work, jobs]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model....\n"
     ]
    }
   ],
   "source": [
    "num_features = 300  # Word vector dimensionality\n",
    "min_word_count = 3 # Minimum word count\n",
    "num_workers = 4     # Number of parallel threads\n",
    "context = 3        # Context window size\n",
    "downsampling = 1e-3 # (0.001) Downsample setting for frequent words\n",
    "\n",
    "# Initializing the train model\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model....\")\n",
    "model = word2vec.Word2Vec(tok_reviews,\\\n",
    "                          workers=num_workers,\\\n",
    "                          size=num_features,\\\n",
    "                          min_count=min_word_count,\\\n",
    "                          window=context,\n",
    "                          sample=downsampling)\n",
    "\n",
    "# To make the model memory efficient\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# Saving the model for later use. Can be loaded using Word2Vec.load()\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = gensim.models.Word2Vec.load('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('remote', 0.9186325073242188),\n",
       " ('arrangement', 0.9027407169342041),\n",
       " ('remotely', 0.8952901363372803),\n",
       " ('close', 0.8744305968284607),\n",
       " ('flexibility', 0.8671191930770874),\n",
       " ('ability', 0.8670336008071899),\n",
       " ('schedule', 0.8513563871383667),\n",
       " ('schedules', 0.8484823703765869),\n",
       " ('compressed', 0.8381692171096802),\n",
       " ('arrangements', 0.8299863338470459)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('home')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03377626 -0.01819777 -0.01754741 -0.04460302 -0.01786285  0.06017548\n",
      "  0.04980672  0.01641134  0.06767074  0.01402638  0.06533532 -0.00359033\n",
      "  0.08907183 -0.05239775  0.00646814 -0.00147883 -0.06832053  0.01136162\n",
      " -0.02340017  0.01045318  0.05648714  0.01041333 -0.06664628 -0.08295068\n",
      "  0.02064369  0.04487361  0.07686536 -0.0808038  -0.04493472 -0.04452851\n",
      " -0.00741632  0.05945476  0.01566405  0.01923566 -0.03968652  0.02115248\n",
      "  0.0373999  -0.02503275 -0.06903453 -0.02365107 -0.04626999 -0.00290489\n",
      " -0.06158046 -0.0166582  -0.08856279  0.03584373  0.03796189  0.03374622\n",
      "  0.04027409  0.04542462 -0.02814871  0.03083507  0.14288293 -0.01458513\n",
      "  0.09228542  0.11613233 -0.03448578 -0.08415332 -0.02876488 -0.13764526\n",
      "  0.01512539  0.03431089  0.01553581 -0.00954222  0.01192343  0.02318529\n",
      " -0.01879531  0.00570917  0.01411439 -0.00880946  0.01481309 -0.05939163\n",
      " -0.06698534  0.05418802  0.06306943 -0.15331163 -0.08073255  0.07379588\n",
      "  0.0051581  -0.06208843  0.01275224  0.07656609  0.09086309 -0.07930297\n",
      " -0.01744866 -0.10005748  0.03484618  0.00666882 -0.04304966 -0.07671933\n",
      "  0.00261334  0.08590768  0.00361458  0.05003968 -0.14442158  0.01609821\n",
      " -0.02345677 -0.0468421  -0.06292114 -0.0632289  -0.00529496  0.00990922\n",
      " -0.03510672 -0.05831729 -0.06574329  0.01157387  0.05596347 -0.02825685\n",
      "  0.05422658 -0.09461442 -0.10141117  0.03090776  0.09821808  0.01756362\n",
      "  0.03177545  0.04915332  0.00684681  0.02411168  0.12872487  0.1715084\n",
      " -0.01473054 -0.0781033  -0.04215053 -0.01429131 -0.04330249  0.05172059\n",
      " -0.05726927 -0.02134871  0.03194406  0.03075296 -0.0598115   0.07646307\n",
      " -0.10185598 -0.00884285 -0.07284805 -0.06093114 -0.02328675 -0.09509759\n",
      "  0.0529785  -0.06080911 -0.02800857  0.12026162  0.04028025 -0.03399476\n",
      " -0.06126405  0.03291144 -0.06708965  0.03494895 -0.14295684  0.10486749\n",
      "  0.01567616 -0.00283406  0.02977658  0.00698008  0.04364497  0.02684876\n",
      "  0.00388064  0.05227355  0.03651713  0.00867281  0.02452769 -0.0113145\n",
      "  0.00384111  0.01740292 -0.0328184  -0.08021379  0.01531127 -0.13727131\n",
      " -0.03929144 -0.02212667 -0.04424666  0.04963034  0.06984877 -0.00634654\n",
      " -0.11489156  0.07441249 -0.00156826  0.02448235  0.10013979 -0.07934878\n",
      " -0.06428798 -0.04179956  0.03441141  0.00172034  0.02718086  0.04172723\n",
      " -0.01668577 -0.00401233  0.02567602 -0.00688395 -0.00884543  0.07622152\n",
      " -0.01523509 -0.01876932  0.05199159 -0.04512252 -0.03176786  0.02535732\n",
      " -0.01129017 -0.06969337  0.0937274  -0.0088936   0.00233896 -0.00339245\n",
      "  0.04029633 -0.02623402 -0.10672188  0.00092673 -0.03383279  0.00798173\n",
      " -0.00208007  0.04049347  0.04835911 -0.04555059 -0.0301585   0.00394549\n",
      " -0.01923421  0.03752983  0.02278835 -0.00528527 -0.0069987   0.00430242\n",
      "  0.04627287 -0.09894182  0.06580731 -0.08293494  0.0893136  -0.00071183\n",
      " -0.06955422  0.09870086 -0.02759014 -0.02276019 -0.02647803 -0.01582312\n",
      " -0.07800017 -0.00061052 -0.15870568  0.00493625  0.00721228  0.12975381\n",
      "  0.01422957 -0.04842187 -0.05199647 -0.09297813  0.00190539  0.04520315\n",
      "  0.05444375  0.03301872 -0.04646981  0.02440323  0.02952937 -0.08208037\n",
      " -0.09706946  0.07606097 -0.00921532 -0.10480522  0.05593995 -0.01936807\n",
      "  0.00306157 -0.02339743  0.02664005  0.02953232  0.03084193 -0.09472205\n",
      " -0.06247219 -0.09710896 -0.03441573 -0.09365653  0.08524445 -0.10375175\n",
      "  0.07938293 -0.02618696  0.03327766  0.02752256 -0.10234232 -0.02451892\n",
      " -0.06350947  0.0721566   0.00408753  0.08353903 -0.04396552 -0.08310603\n",
      " -0.05646927  0.01324625  0.0874508  -0.06229582 -0.02917819  0.13047434\n",
      " -0.04948226  0.04020874 -0.00445859  0.00033364  0.04570573  0.04844829\n",
      "  0.09799301 -0.00855717  0.03144393  0.00160766 -0.02384209  0.11318748]\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(model['friendly'])\n",
    "print(model[\"friendly\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=3324, size=250, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureVecMethod(words, model, num_features):\n",
    "    # Pre-initialising empty numpy array for speed\n",
    "    featureVec = np.zeros(num_features,dtype=\"float32\")\n",
    "    nwords = 0\n",
    "    \n",
    "    #Converting Index2Word which is a list to a set for better speed in the execution.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in  words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    \n",
    "    # Dividing the result by number of words to get average\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating the average feature vector\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    counter = 0\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    for review in reviews:\n",
    "        # Printing a status message every 1000th review\n",
    "        if counter%1000 == 0:\n",
    "            print(\"Review %d of %d\"%(counter,len(reviews)))\n",
    "            \n",
    "        reviewFeatureVecs[counter] = featureVecMethod(review, model, num_features)\n",
    "        counter = counter+1\n",
    "        \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 33624\n",
      "Review 1000 of 33624\n",
      "Review 2000 of 33624\n",
      "Review 3000 of 33624\n",
      "Review 4000 of 33624\n",
      "Review 5000 of 33624\n",
      "Review 6000 of 33624\n",
      "Review 7000 of 33624\n",
      "Review 8000 of 33624\n",
      "Review 9000 of 33624\n",
      "Review 10000 of 33624\n",
      "Review 11000 of 33624\n",
      "Review 12000 of 33624\n",
      "Review 13000 of 33624\n",
      "Review 14000 of 33624\n",
      "Review 15000 of 33624\n",
      "Review 16000 of 33624\n",
      "Review 17000 of 33624\n",
      "Review 18000 of 33624\n",
      "Review 19000 of 33624\n",
      "Review 20000 of 33624\n",
      "Review 21000 of 33624\n",
      "Review 22000 of 33624\n",
      "Review 23000 of 33624\n",
      "Review 24000 of 33624\n",
      "Review 25000 of 33624\n",
      "Review 26000 of 33624\n",
      "Review 27000 of 33624\n",
      "Review 28000 of 33624\n",
      "Review 29000 of 33624\n",
      "Review 30000 of 33624\n",
      "Review 31000 of 33624\n",
      "Review 32000 of 33624\n",
      "Review 33000 of 33624\n"
     ]
    }
   ],
   "source": [
    "# # Calculating average feature vector for training set\n",
    "# clean_train_reviews = []\n",
    "# for review in train['review']:\n",
    "#     clean_train_reviews.append(review_wordlist(review, remove_stopwords=True))\n",
    "\n",
    "num_features = 300\n",
    "trainDataVecs = getAvgFeatureVecs(tok_reviews, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33624, 300)\n"
     ]
    }
   ],
   "source": [
    "X = trainDataVecs\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-0d4a9370a8e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnum_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    969\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m                 return_n_iter=True)\n\u001b[0m\u001b[1;32m    972\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, sample_weight, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"C\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy_x\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     X = check_array(X, accept_sparse='csr', dtype=[np.float64, np.float32],\n\u001b[0;32m--> 311\u001b[0;31m                     order=order, copy=copy_x)\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0;31m# verify that the number of samples given is larger than k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 573\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "# KMeans Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_cluster = 8 \n",
    "kmeans = KMeans(n_clusters=num_cluster).fit(X)\n",
    "\n",
    "for k in range(8):\n",
    "    wv = kmeans.cluster_centers_[k]\n",
    "    print(f\"Cluster {k}: \")\n",
    "    similar_words = model.most_similar(positive=[wv], topn=30)\n",
    "    print([x[0] for x in similar_words])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3324, 250)\n"
     ]
    }
   ],
   "source": [
    "# print(vec.wv.vocab)\n",
    "X = model[model.wv.vocab]\n",
    "print(model[model.wv.vocab].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "feat_name = model.wv.vocab\n",
    "print(feat_name[\"great\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))\n",
    "w2v[\"management\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2375\n"
     ]
    }
   ],
   "source": [
    "print(len(w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2375, 250)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans Clustering\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_cluster = 8 \n",
    "kmeans = KMeans(n_clusters=8).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: \n",
      "['reports', 'testing', 'trust', 'creativity', 'track', 'improving', 'operation', 'valued', 'project', 'everybody', 'system', 'efforts', 'perfect', 'design', 'previous', 'encouragement', 'goal', 'opinion', 'ahead', 'current', 'presence', 'promoted', 'proud', 'excellence', 'problem', 'lean', 'mgmt', 'theyre', 'levels', 'calls']\n",
      "\n",
      "Cluster 1: \n",
      "['los', 'date', 'en', 'oracle', 'say', 'standards', 'wasnt', 'beneficios', 'tier', 'automated', 'guidelines', 'abilities', 'follow', 'hit', 'anyone', 'comes', 'lines', 'serving', 'closing', 'bringing', 'basically', 'contracts', 'distance', 'arent', 'hotels', 'ups', 'seguro', 'gives', 'appropriate', 'usa']\n",
      "\n",
      "Cluster 2: \n",
      "['conditions', 'colleagues', 'peers', 'supportive', 'collaborative', 'stable', 'managment', 'push', 'safe', 'understanding', 'teamwork', 'level', 'oriented', 'overall', 'fantastic', 'caring', 'enviornment', 'respectful', 'diverse', 'enjoyable', 'spirit', 'solid', 'workplace', 'rewarding', 'mentality', 'high', 'positive', 'evolving', 'pleasant', 'position']\n",
      "\n",
      "Cluster 3: \n",
      "['en', 'los', 'date', 'standards', 'say', 'tier', 'oracle', 'wasnt', 'abilities', 'beneficios', 'automated', 'closing', 'guidelines', 'anyone', 'seguro', 'hit', 'towards', 'serving', 'follow', 'de', 'distance', 'ups', 'complete', 'hotels', 'basically', 'target', 'contracts', 'lines', 'comes', 'arent']\n",
      "\n",
      "Cluster 4: \n",
      "['half', 'shift', 'hr', 'two', 'per', 'weekends', 'shifts', 'four', 'min', 'minute', 'sundays', 'unpaid', 'minutes', 'three', 'short', 'early', 'one', 'fifteen', 'months', 'period', 'mandatory', 'breaks', 'holidays', 'take', 'times', 'week', 'hour', 'mins', 'long', 'extra']\n",
      "\n",
      "Cluster 5: \n",
      "['help', 'things', 'something', 'learned', 'business', 'techniques', 'technologies', 'alot', 'everyday', 'types', 'making', 'make', 'cutting', 'try', 'edge', 'gain', 'interaction', 'challenges', 'met', 'interacting', 'faces', 'skills', 'develop', 'friends', 'exciting', 'lot', 'clients', 'daily', 'different', 'technology']\n",
      "\n",
      "Cluster 6: \n",
      "['pension', 'coverage', 'espp', 'matching', 'match', 'retirement', 'healthcare', 'profit', 'generous', 'assistance', 'k', 'vision', 'sharing', 'plan', 'plans', 'dental', 'stocks', 'union', 'medical', 'stock', 'college', 'purchase', 'raises', 'timers', 'including', 'program', 'ins', 'contributions', 'options', 'yearly']\n",
      "\n",
      "Cluster 7: \n",
      "['chocolate', 'occasionally', 'special', 'starbucks', 'beverages', 'snack', 'tea', 'dinners', 'donuts', 'fruits', 'sodas', 'gifts', 'hot', 'occasions', 'soft', 'ice', 'tickets', 'drink', 'pizza', 'tshirts', 'raffles', 'prizes', 'meal', 'water', 'fountain', 'fresh', 'pong', 'cup', 'sometime', 'bar']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(8):\n",
    "    wv = kmeans.cluster_centers_[k]\n",
    "    print(f\"Cluster {k}: \")\n",
    "    similar_words = model.most_similar(positive=[wv], topn=30)\n",
    "    print([x[0] for x in similar_words])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33624\n"
     ]
    }
   ],
   "source": [
    "def getWordVecs(words):\n",
    "    vecs = []\n",
    "    for word in words:\n",
    "        word = word.replace('\\n', '')\n",
    "        try:\n",
    "            vecs.append(model[word])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return np.array(vecs, dtype='float')\n",
    "\n",
    "\n",
    "X = []\n",
    "for words in tok_reviews: \n",
    "    word_vecs = getWordVecs(words)\n",
    "    mean_wv = np.round(np.mean(word_vecs, axis=0), 2)\n",
    "    X.append(mean_wv.tolist())\n",
    "    \n",
    "# print(X)\n",
    "# print(X)\n",
    "# print(len(X))\n",
    "# print(len(X[0]))\n",
    "# X = np.asarray(X) \n",
    "# print(X.shape)\n",
    "# X = X.tolist()\n",
    "# print(X[:5])\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "print(len(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "#                [10, 2], [10, 4], [10, 0]]).tolist()\n",
    "# print(X)\n",
    "# kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "# kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c7c48674ed26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    969\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m                 return_n_iter=True)\n\u001b[0m\u001b[1;32m    972\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, sample_weight, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"C\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy_x\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     X = check_array(X, accept_sparse='csr', dtype=[np.float64, np.float32],\n\u001b[0;32m--> 311\u001b[0;31m                     order=order, copy=copy_x)\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0;31m# verify that the number of samples given is larger than k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# KMeans Clustering\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_cluster = 8 \n",
    "kmeans = KMeans(n_clusters=8, random_state =42).fit(X)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: \n",
      "['en', 'los', 'date', 'standards', 'say', 'tier', 'oracle', 'wasnt', 'abilities', 'beneficios', 'automated', 'closing', 'guidelines', 'anyone', 'seguro', 'hit', 'towards', 'serving', 'follow', 'de', 'distance', 'ups', 'complete', 'hotels', 'basically', 'target', 'contracts', 'lines', 'comes', 'arent']\n",
      "\n",
      "Cluster 1: \n",
      "['dinners', 'dinner', 'occasions', 'gifts', 'occasionally', 'chocolate', 'catered', 'parties', 'special', 'sometime', 'pizza', 'snack', 'donuts', 'often', 'ice', 'tea', 'cards', 'prizes', 'sodas', 'raffles', 'hot', 'water', 'give', 'fridays', 'cup', 'yes', 'popcorn', 'tshirts', 'certain', 'pot']\n",
      "\n",
      "Cluster 2: \n",
      "['reports', 'testing', 'track', 'trust', 'creativity', 'improving', 'operation', 'previous', 'everybody', 'system', 'valued', 'efforts', 'current', 'excellence', 'proud', 'project', 'opinion', 'institution', 'lean', 'calls', 'encouragement', 'ahead', 'perfect', 'goal', 'volunteering', 'design', 'built', 'presence', 'promoted', 'la']\n",
      "\n",
      "Cluster 3: \n",
      "['los', 'date', 'en', 'oracle', 'say', 'standards', 'beneficios', 'wasnt', 'tier', 'automated', 'guidelines', 'abilities', 'follow', 'hit', 'comes', 'anyone', 'lines', 'serving', 'closing', 'bringing', 'basically', 'distance', 'contracts', 'arent', 'hotels', 'ups', 'gives', 'seguro', 'de', 'appropriate']\n",
      "\n",
      "Cluster 4: \n",
      "['safe', 'enviroment', 'enjoyable', 'enviornment', 'pleasant', 'manager', 'caring', 'helpful', 'understanding', 'conditions', 'managers', 'relaxed', 'supervisors', 'comfortable', 'clean', 'collaborative', 'peers', 'mostly', 'members', 'managment', 'workplace', 'respectful', 'pretty', 'location', 'generally', 'friendship', 'rewarding', 'welcoming', 'positive', 'colleagues']\n",
      "\n",
      "Cluster 5: \n",
      "['things', 'learned', 'help', 'something', 'alot', 'techniques', 'technologies', 'everyday', 'business', 'types', 'making', 'lot', 'gain', 'skills', 'cutting', 'try', 'different', 'make', 'new', 'met', 'edge', 'challenges', 'meeting', 'develop', 'interaction', 'clients', 'daily', 'faces', 'interacting', 'meet']\n",
      "\n",
      "Cluster 6: \n",
      "['pension', 'generous', 'coverage', 'espp', 'raises', 'match', 'matching', 'healthcare', 'stocks', 'union', 'profit', 'k', 'assistance', 'sharing', 'vision', 'retirement', 'pto', 'college', 'plans', 'timers', 'purchase', 'including', 'yearly', 'dental', 'vacations', 'plan', 'bonus', 'vaction', 'medical', 'stock']\n",
      "\n",
      "Cluster 7: \n",
      "['leadership', 'strong', 'development', 'compensation', 'training', 'educational', 'potential', 'culture', 'resources', 'mobility', 'overall', 'path', 'continued', 'career', 'high', 'education', 'excellent', 'diversity', 'advance', 'stable', 'support', 'growth', 'within', 'solid', 'promotion', 'paths', 'diverse', 'security', 'scale', 'travel']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(8):\n",
    "    wv = kmeans.cluster_centers_[k]\n",
    "    print(f\"Cluster {k}: \")\n",
    "    similar_words = model.most_similar(positive=[wv], topn=30)\n",
    "    print([x[0] for x in similar_words])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lengths'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-c7b2f963fd2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m             ])\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeanEmbeddingVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-083f3e2b0407>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         return np.array([\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         ])\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-083f3e2b0407>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         return np.array([\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         ])\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-083f3e2b0407>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         return np.array([\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         ])\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lengths'"
     ]
    }
   ],
   "source": [
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])\n",
    "    \n",
    "X = MeanEmbeddingVectorizer(w2v).transform(tok_reviews)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.64312103e-02 -1.05516350e+00  6.32314920e-01 ... -4.19578135e-01\n",
      "  -9.47186574e-02 -9.00793225e-02]\n",
      " [ 1.24626994e-01 -7.37552404e-01  7.97648311e-01 ... -1.97177410e-01\n",
      "   2.52673984e-01 -3.24843340e-02]\n",
      " [-1.64543808e-01 -1.43813461e-01  8.59050751e-01 ... -3.57315361e-01\n",
      "  -1.08184934e-01 -3.48016471e-01]\n",
      " ...\n",
      " [ 1.49584606e-01 -1.77112997e-01  2.07249418e-01 ... -9.37697515e-02\n",
      "   1.88930966e-02 -3.09132729e-02]\n",
      " [ 2.31011640e-02 -3.12778465e-02  4.33276109e-02 ... -1.54834120e-02\n",
      "   9.78356460e-04 -1.26754455e-02]\n",
      " [ 1.33182425e-02 -1.75118390e-02  3.15653160e-02 ... -1.65539254e-02\n",
      "  -6.03470765e-03 -7.06415856e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans Clustering\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_cluster = 8 \n",
    "kmeans = KMeans(n_clusters=8).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: \n",
      "['r', 'desks', 'volunteering', 'america', 'nothing', 'knows', 'wish', 'towards', 'heat', 'gm', 'offerings', 'abilities', 'shirt', 'heavy', 'front', 'national', 'complete', 'board', 'street', 'networks', 'console', 'news', 'cant', 'hotels', 'contractor', 'excellence', 'fund', 'less', 'la', 'can']\n",
      "\n",
      "Cluster 1: \n",
      "['safe', 'enviroment', 'pleasant', 'colleagues', 'envirnment', 'workplace', 'enviornment', 'enjoyable', 'knowledgeable', 'collaborative', 'supportive', 'conditions', 'caring', 'understanding', 'manager', 'collaborations', 'peers', 'cooperative', 'wholesome', 'managers', 'players', 'managerial', 'personable', 'honest', 'rewarding', 'clean', 'location', 'enviorment', 'generally', 'mostly']\n",
      "\n",
      "Cluster 2: \n",
      "['half', 'unpaid', 'shift', 'four', 'shifts', 'hr', 'per', 'minute', 'weekends', 'two', 'minutes', 'sundays', 'min', 'short', 'fifteen', 'accrue', 'mins', 'thirty', 'one', 'mandatory', 'three', 'early', 'andor', 'seperate', 'months', 'week', 'hrs', 'long', 'according', 'hour']\n",
      "\n",
      "Cluster 3: \n",
      "['employer', 'reports', 'talents', 'control', 'think', 'tough', 'say', 'perfect', 'mae', 'peoples', 'banks', 'problem', 'economy', 'documentation', 'minds', 'expectations', 'easily', 'appreciated', 'fannie', 'pride', 'flights', 'lean', 'lines', 'increasing', 'accessible', 'hire', 'units', 'responsibility', 'educated', 'still']\n",
      "\n",
      "Cluster 4: \n",
      "['business', 'knowledge', 'build', 'cutting', 'technologies', 'edge', 'curve', 'gain', 'gained', 'applying', 'develop', 'experiences', 'technology', 'supervisory', 'exposure', 'technical', 'skills', 'move', 'challenges', 'improve', 'improvement', 'grow', 'financial', 'industry', 'network', 'competencies', 'stack', 'exciting', 'valuable', 'progress']\n",
      "\n",
      "Cluster 5: \n",
      "['pension', 'matching', 'union', 'healthcare', 'assistance', 'coverage', 'generous', 'profit', 'match', 'retirement', 'plans', 'accrual', 'hsa', 'sharing', 'college', 'stocks', 'grants', 'plan', 'k', 'medical', 'healthdental', 'espp', 'vision', 'dental', 'raises', 'stock', 'reimbursements', 'ins', 'options', 'reimbursment']\n",
      "\n",
      "Cluster 6: \n",
      "['occasions', 'juice', 'special', 'breakroom', 'dinners', 'fruits', 'hot', 'serves', 'beverages', 'raffles', 'soft', 'water', 'cup', 'sodas', 'fountain', 'nachos', 'tickets', 'drink', 'gifts', 'tvs', 'aways', 'chocolate', 'pizza', 'vending', 'occasionally', 'cofee', 'lunchsnacks', 'accidents', 'sandwich', 'dinner']\n",
      "\n",
      "Cluster 7: \n",
      "['r', 'knows', 'front', 'desks', 'abilities', 'heavy', 'nothing', 'console', 'national', 'less', 'america', 'volunteering', 'hotels', 'wish', 'offerings', 'heat', 'effective', 'due', 'white', 'board', 'infinite', 'think', 'exam', 'networks', 'towards', 'say', 'excellence', 'gm', 'till', 'listened']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(8):\n",
    "    wv = kmeans.cluster_centers_[k]\n",
    "    print(f\"Cluster {k}: \")\n",
    "    similar_words = model.most_similar(positive=[wv], topn=30)\n",
    "    print([x[0] for x in similar_words])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out LDA on different pre-processed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_px = df.Tknz_Texts1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9177\n",
      "Dictionary(9177 unique tokens: ['coworkers', 'friendly', 'hour', 'lunch', 'benefits']...)\n",
      "[[(0, 1), (1, 1), (2, 1), (3, 1)], [(4, 1), (5, 1), (6, 1), (7, 1), (8, 1)], [(9, 1), (10, 1), (11, 1)], [(12, 1), (13, 1), (14, 1), (15, 1), (16, 1)], [(11, 1), (13, 1), (17, 1), (18, 1), (19, 1), (20, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_px)\n",
    "print(len(id2word))\n",
    "print(id2word)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_px\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "# print(corpus[:1])\n",
    "print(corpus[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_path = '~/Downloads/mallet-2.0.8/bin/mallet' # update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=10, id2word=id2word, iterations=500, \n",
    "                                            random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.31431422041183954\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=ldamallet, texts=data_px, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "##mallet model to lda model conversion\n",
    "\n",
    "optimal_model = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el42591122535964408501049198\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el42591122535964408501049198_data = {\"mdsDat\": {\"x\": [-0.09371992466012868, -0.08476776684764101, -0.043811720500625984, -0.04029016622465444, 0.006930788317311205, 0.1996099683626112, -0.24944030878323858, 0.2790143053128122, 0.27721958531731655, -0.2507447602937628], \"y\": [-0.13742021309485514, -0.030520078676952254, 0.04084932302533335, -0.21107654714146856, -0.2957219853377566, -0.10132728006200929, 0.19017938720766703, 0.18060738009437738, 0.16766291186917204, 0.19676710211649168], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [10.047077199485335, 10.036695181727568, 10.021786137873944, 10.019654878271183, 10.018794833391793, 10.007427608761098, 9.975925613269457, 9.96894829551852, 9.952361726230862, 9.951328525470228]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"Freq\": [5415.0, 5129.0, 9034.0, 5589.0, 7119.0, 5452.0, 2497.0, 3018.0, 2220.0, 2253.0, 2080.0, 1892.0, 1724.0, 1647.0, 1540.0, 1437.0, 1383.0, 1265.0, 1256.0, 1591.0, 1214.0, 1206.0, 1143.0, 1131.0, 1112.0, 1103.0, 1112.0, 1300.0, 1052.0, 1066.0, 1.0824601714657889, 7.5772212002605235, 1.0824601714657889, 1.0824601714657889, 7.5772212002605235, 1.0824601714657889, 1.0824601714657889, 20.566743257849993, 1.0824601714657889, 10.82460171465789, 3.247380514397367, 1.0824601714657889, 3.247380514397367, 3.247380514397367, 1.0824601714657889, 3.247380514397367, 3.247380514397367, 9.742141543192101, 5.412300857328945, 1.0824601714657889, 14.071982229055259, 5.412300857328945, 11.90706188612368, 1.0824601714657889, 1.0824601714657889, 28.143964458110517, 9.742141543192101, 1.0824601714657889, 1.0824601714657889, 19.484283086384202, 1029.4196230639654, 744.7325979684629, 593.1881739632523, 592.1057137917866, 470.87017458761824, 357.21185658371036, 303.0888480104209, 290.09932595283146, 274.9448835523104, 237.0587775510078, 227.3166360078157, 203.50251223556833, 201.33759189263677, 162.36902571986835, 150.46196383374468, 143.96720280494995, 140.71982229055257, 127.73030023296312, 126.64784006149732, 120.15307903270259, 120.15307903270259, 117.98815868977101, 113.65831800390785, 110.41093748951049, 110.41093748951049, 108.24601714657891, 108.24601714657891, 106.08109680364733, 102.83371628924996, 97.42141543192102, 261.955361494721, 126.64784006149732, 2410.638801854312, 139.6373621190868, 117.98815868977101, 114.74077817537365, 385.3558210418209, 138.55490194762098, 114.74077817537365, 13.968587344452903, 7.5215470316284865, 30.086188126513946, 7.5215470316284865, 7.5215470316284865, 27.937174688905806, 78.43899047269707, 7.5215470316284865, 7.5215470316284865, 39.756748595750565, 7.5215470316284865, 13.968587344452903, 7.5215470316284865, 13.968587344452903, 74.14096359748079, 15.043094063256973, 7.5215470316284865, 7.5215470316284865, 366.4067911121877, 354.58721720534294, 571.6375744037649, 1143.2751488075298, 702.7273940978614, 55.87434937781161, 186.9641690719081, 1.0745067188040696, 1.0745067188040696, 1.0745067188040696, 1.0745067188040696, 1.0745067188040696, 5414.439356053706, 2228.52693479964, 1061.6126381784206, 1105.6674136493875, 210.60331688559762, 203.08176985396912, 162.2505145394145, 140.7603801633331, 95.63109797356219, 90.25856437954184, 80.58800391030522, 77.364483753893, 75.21547031628486, 64.47040312824417, 53.72533594020347, 51.57632250259533, 51.57632250259533, 47.27829562737906, 44.054775470966845, 40.83125531455464, 40.83125531455464, 116.0467256308395, 116.0467256308395, 76.28997703508894, 257.8816125129767, 125.71728610007614, 74.14096359748079, 495.3475973686761, 74.14096359748079, 101.00363156758253, 1.0847152287848807, 3.2541456863546423, 2.1694304575697614, 1.0847152287848807, 1.0847152287848807, 4.338860915139523, 8.677721830279046, 3.2541456863546423, 1.0847152287848807, 2.1694304575697614, 42.30389392261034, 6.508291372709285, 32.54145686354642, 1.0847152287848807, 1.0847152287848807, 1.0847152287848807, 1.0847152287848807, 1.0847152287848807, 2.1694304575697614, 4.338860915139523, 1.0847152287848807, 2.1694304575697614, 9.762437059063926, 5.423576143924403, 3.2541456863546423, 1.0847152287848807, 1.0847152287848807, 3.2541456863546423, 1.0847152287848807, 3.2541456863546423, 2497.0144566627955, 1647.6824325242337, 1014.2087389138635, 720.2509119131608, 705.0648987101724, 498.96900524104507, 421.95422399731854, 488.1218529531963, 361.21017118536525, 276.60238334014457, 269.00937673865036, 260.3316549083714, 649.7444220421435, 225.62076758725516, 220.19719144333078, 273.3482376537899, 169.21557569044137, 151.8601320298833, 144.26712542838914, 142.09769497081936, 141.0129797420345, 126.91168176783103, 124.74225131026127, 116.06452947998223, 113.89509902241247, 111.72566856484272, 188.74044980856922, 99.79380104820902, 99.79380104820902, 93.28550967549974, 395.9210585064814, 214.77361529940637, 127.99639699661591, 171.38500614801114, 188.74044980856922, 127.99639699661591, 164.87671477530188, 141.0129797420345, 1.0655956302727743, 1.0655956302727743, 1.0655956302727743, 2.1311912605455485, 4.262382521091097, 14.918338823818841, 8.524765042182194, 1.0655956302727743, 1.0655956302727743, 1.0655956302727743, 1.0655956302727743, 1.0655956302727743, 18.115125714637163, 3.196786890818323, 6.393573781636646, 3.196786890818323, 1.0655956302727743, 3.196786890818323, 27.70548638709213, 1.0655956302727743, 4.262382521091097, 22.377508235728257, 1.0655956302727743, 3.196786890818323, 8.524765042182194, 1.0655956302727743, 1.0655956302727743, 5.3279781513638715, 4.262382521091097, 1.0655956302727743, 1265.927608764056, 1112.4818380047764, 1103.9570729625943, 855.6732911090378, 821.5742309403089, 726.7362198460321, 686.2435858956667, 499.7643505979311, 655.3413126177562, 414.51670017610917, 472.05886421083903, 297.30118084610405, 254.67735563519307, 215.25031731510043, 180.08566151609887, 170.4953008436439, 254.67735563519307, 152.38017512900672, 143.85541008682455, 141.72421882627899, 284.5140332828307, 121.47790185109628, 112.95313680891407, 95.90360672454969, 82.05086353100363, 76.72288537963975, 68.19812033745755, 67.13252470718479, 67.13252470718479, 63.93573781636646, 127.87147563273292, 105.49396739700467, 216.31591294537319, 376.1552574862893, 182.2168527766444, 142.78981445655177, 296.23558521583124, 309.02273277910456, 479.5180336227484, 160.9049401711889, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 5.282240354165585, 1.0564480708331168, 1.0564480708331168, 3.1693442124993507, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 3.1693442124993507, 1.0564480708331168, 3.1693442124993507, 1.0564480708331168, 1.0564480708331168, 3.1693442124993507, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 4.225792283332467, 1214.9152814580846, 1206.4636968914194, 1535.0190469205188, 552.52234104572, 483.8532164415675, 455.32911852907336, 526.1111392748923, 428.91791675824544, 356.0229998707604, 257.77332928328053, 252.49108892911494, 251.4346408582818, 217.62830259162206, 379.2648574290889, 209.17671802495715, 165.86234712079937, 159.52365869580066, 116.20928779164285, 61.27398810832078, 61.27398810832078, 177.48327589996364, 48.59661125832338, 44.37081897499091, 113.03994357914351, 42.25792283332468, 41.20147476249156, 39.088578620825324, 38.0321305499922, 36.97568247915909, 33.806338266659736, 85.57229373748247, 78.17715724165065, 81.34650145415, 1271.9634772830727, 70.78202074581883, 4182.4779124283095, 115.15283972080974, 161.6365548374669, 213.40251030828964, 607.4576407290423, 124.66087235830778, 80.29005338331689, 20.660425295202888, 13.04868966012814, 3.262172415032035, 13.04868966012814, 3.262172415032035, 13.04868966012814, 14.13608046513882, 6.52434483006407, 13.04868966012814, 13.04868966012814, 35.88389656535239, 20.660425295202888, 14.13608046513882, 3.262172415032035, 13.04868966012814, 13.04868966012814, 3.262172415032035, 3.262172415032035, 14.13608046513882, 3.262172415032035, 13.04868966012814, 3.262172415032035, 13.04868966012814, 6.52434483006407, 50.019977030491205, 13.04868966012814, 41.320850590405776, 3.262172415032035, 6.52434483006407, 3.262172415032035, 1052.5942992503367, 1039.5456095902084, 382.7615633637588, 433.86893119926066, 308.8189886230327, 284.89639091279776, 270.7603104476589, 253.36205756748805, 417.5580691241005, 247.9251035424347, 462.1410921295383, 227.26467824723179, 227.26467824723179, 166.37079316663377, 155.496885116527, 129.39950579627072, 110.91386211108919, 188.11860926684736, 104.38951728102512, 101.12734486599308, 101.12734486599308, 91.34082762089697, 79.37952876577953, 75.02996554573681, 73.94257474072613, 145.7103678714309, 64.15605749563002, 60.89388508059799, 58.719103470576634, 55.456931055544594, 101.12734486599308, 80.46691957079021, 1138.4981728461803, 159.84644833656972, 242.4881495173813, 856.8639543484145, 456.7041381044849, 2457.503219324133, 1650.6592420062098, 46.40868305696858, 167.28711334488673, 3.237815096997808, 3.237815096997808, 12.951260387991232, 3.237815096997808, 3.237815096997808, 3.237815096997808, 44.25013965897004, 3.237815096997808, 3.237815096997808, 3.237815096997808, 26.98179247498173, 3.237815096997808, 26.98179247498173, 22.664705678984657, 3.237815096997808, 6.475630193995616, 3.237815096997808, 3.237815096997808, 6.475630193995616, 6.475630193995616, 3.237815096997808, 26.98179247498173, 22.664705678984657, 31.29887927097881, 3.237815096997808, 3.237815096997808, 12.951260387991232, 3.237815096997808, 1722.5176316028337, 1033.9422876413, 1129.997468852235, 2060.329673389605, 467.3246456666836, 446.8184833856975, 472.72100416167996, 306.51316251579254, 265.5008379538202, 261.18375115782317, 251.47030586682976, 195.34817751886774, 194.26890581986848, 192.11036242186995, 181.31764543187725, 150.01876616089842, 138.1467774719065, 127.35406048191378, 127.35406048191378, 120.87843028791816, 102.53081140493059, 94.97590951193571, 91.73809441493789, 86.34173591994154, 80.9453774249452, 78.78683402694666, 76.62829062894814, 72.31120383295105, 72.31120383295105, 843.9904686174285, 72.31120383295105, 2971.2349873449884, 115.48207179292181, 84.18319252194301, 7.347603668115073, 7.347603668115073, 7.347603668115073, 32.53938767308104, 75.57535201489789, 7.347603668115073, 14.695207336230146, 132.25686602607132, 104.96576668735818, 9.446919001862236, 94.46919001862236, 14.695207336230146, 7.347603668115073, 7.347603668115073, 7.347603668115073, 26.241441671839546, 1.049657666873582, 1.049657666873582, 1.049657666873582, 2.099315333747164, 1.049657666873582, 1.049657666873582, 1.049657666873582, 1.049657666873582, 1.049657666873582, 1.049657666873582, 1.049657666873582, 2.099315333747164, 1.049657666873582, 1.049657666873582, 5129.677018011194, 1033.9128018704782, 248.76886704903893, 149.05138869604863, 226.7260560446937, 123.85960469108267, 103.9161090204846, 86.07192868363371, 62.97946001241491, 60.88014467866775, 60.88014467866775, 54.582198677426256, 151.15070402979578, 34.6387030068282, 96.56850535236953, 27.291099338713128, 25.191784004965967, 23.092468671218803, 19.943495670598058, 17.844180336850894, 16.79452266997731, 16.79452266997731, 5249.337992034783, 195.23632603848623, 61.92980234554133, 131.20720835919772, 80.82364034926582, 33.58904533995462, 33.58904533995462, 149.05138869604863, 3147.923342953872, 108.11473968797893, 153.25001936354295, 94.46919001862236, 69.2774060136564, 3.2319622697516164, 3.2319622697516164, 3.2319622697516164, 7.541245296087105, 3.2319622697516164, 10.773207565838721, 3.2319622697516164, 5.3866037829193605, 16.159811348758083, 10.773207565838721, 3.2319622697516164, 3.2319622697516164, 3.2319622697516164, 48.47943404627425, 3.2319622697516164, 6.463924539503233, 3.2319622697516164, 7.541245296087105, 72.18049069111943, 15.08249059217421, 3.2319622697516164, 20.469094375093572, 51.71139631602586, 16.159811348758083, 5.3866037829193605, 45.24747177652264, 32.31962269751617, 7.541245296087105, 10.773207565838721, 12.927849079006466, 1437.1458892828855, 1383.279851453692, 624.8460388186459, 623.7687180620621, 572.0573217460361, 400.7633214492005, 343.6653213502553, 305.9590948698197, 259.63430233671323, 809.067888194488, 211.15486829043897, 191.76309467192925, 172.37132105341954, 164.83007575733245, 321.041585461994, 160.520792730997, 150.8249059217421, 148.67026440857438, 138.97437759931952, 116.3506417110582, 105.57743414521948, 237.0105664484519, 81.87637750037429, 351.20656664634237, 75.41245296087105, 68.94852842136783, 64.63924539503233, 56.020679342361355, 53.866037829193615, 363.05709496876494, 112.04135868472271, 102.34547187546787, 148.67026440857438, 4222.020045052195, 147.59294365199048, 188.53113240217766, 276.8714344420552, 118.50528322422595, 119.58260398080982, 1.0883989676678434, 1.0883989676678434, 2.1767979353356868, 1.0883989676678434, 7.618792773674904, 2.1767979353356868, 1.0883989676678434, 1.0883989676678434, 1.0883989676678434, 2.1767979353356868, 1.0883989676678434, 1.0883989676678434, 1.0883989676678434, 1.0883989676678434, 2.1767979353356868, 1.0883989676678434, 1.0883989676678434, 1.0883989676678434, 1.0883989676678434, 1.0883989676678434, 4.3535958706713735, 1.0883989676678434, 1.0883989676678434, 2.1767979353356868, 1.0883989676678434, 1.0883989676678434, 2.1767979353356868, 1.0883989676678434, 1.0883989676678434, 1.0883989676678434, 2220.3338940424005, 1885.1070120007048, 1256.0124086886913, 907.7247390349814, 675.8957589217308, 577.9398518316249, 359.17165933038837, 323.2544933973495, 277.54173675530006, 262.30415120795027, 166.52504205318004, 161.08304721484083, 133.87307302314474, 120.81228541113062, 115.3702905727914, 189.38142037420477, 107.7514977991165, 107.7514977991165, 103.39790192844514, 102.3095029607773, 101.22110399310945, 96.86750812243807, 96.86750812243807, 84.89511947809179, 74.01112980141336, 68.56913496307413, 60.95034218939923, 59.86194322173139, 59.86194322173139, 59.86194322173139, 168.70183998851573, 180.674228632862, 177.4090317298585, 99.04430605777377, 107.7514977991165, 2481.549646282683, 104.48630089611298], \"Term\": [\"work\", \"good\", \"benefits\", \"pay\", \"great\", \"free\", \"time\", \"people\", \"lunch\", \"environment\", \"hours\", \"lunches\", \"flexible\", \"paid\", \"coworkers\", \"health\", \"excellent\", \"team\", \"breaks\", \"management\", \"friendly\", \"nice\", \"balance\", \"food\", \"opportunities\", \"training\", \"fun\", \"company\", \"employees\", \"home\", \"attached\", \"varied\", \"monotony\", \"oxygen\", \"loyal\", \"photo\", \"evaluations\", \"ups\", \"begining\", \"certification\", \"entrylevel\", \"dicount\", \"bottom\", \"ordering\", \"payfull\", \"friendliness\", \"reduce\", \"drugs\", \"round\", \"semiregular\", \"homes\", \"multitask\", \"satisfied\", \"philanthropist\", \"vp\", \"advanced\", \"micromanagement\", \"healt\", \"supervisorcant\", \"responsibilities\", \"job\", \"customers\", \"lot\", \"learn\", \"easy\", \"meeting\", \"skills\", \"security\", \"money\", \"technology\", \"learned\", \"make\", \"busy\", \"safety\", \"daily\", \"friends\", \"everyday\", \"big\", \"interesting\", \"love\", \"hourly\", \"wage\", \"enjoyed\", \"relationships\", \"projects\", \"top\", \"stable\", \"world\", \"boss\", \"edge\", \"helping\", \"goals\", \"people\", \"alot\", \"cool\", \"members\", \"working\", \"sales\", \"freedom\", \"allowing\", \"chose\", \"type\", \"friend\", \"proximity\", \"generally\", \"locations\", \"completed\", \"significant\", \"fastpaced\", \"lifestyle\", \"engaging\", \"closing\", \"wealth\", \"remotely\", \"approachable\", \"learner\", \"deliver\", \"ability\", \"place\", \"worklife\", \"balance\", \"life\", \"pleasant\", \"enviroment\", \"managmen\", \"upword\", \"horizontal\", \"infotainment\", \"actitivies\", \"work\", \"environment\", \"home\", \"fun\", \"hard\", \"positive\", \"smart\", \"remote\", \"jobs\", \"enjoyable\", \"rewarding\", \"solid\", \"healthy\", \"conditions\", \"collaborative\", \"flexable\", \"bad\", \"intelligent\", \"market\", \"telecommute\", \"listen\", \"steady\", \"safe\", \"colleagues\", \"office\", \"diverse\", \"constant\", \"working\", \"teams\", \"challenging\", \"showings\", \"decades\", \"bases\", \"merchandiseing\", \"calloff\", \"saftey\", \"charity\", \"topped\", \"lowstress\", \"hearing\", \"snack\", \"pricing\", \"unpaid\", \"discouts\", \"foremen\", \"hippa\", \"futher\", \"utiilzed\", \"acess\", \"exceeds\", \"realy\", \"happen\", \"increased\", \"grill\", \"noon\", \"wallet\", \"hightech\", \"mini\", \"workbalance\", \"pods\", \"time\", \"paid\", \"vacation\", \"discount\", \"days\", \"overtime\", \"pto\", \"holidays\", \"week\", \"full\", \"sick\", \"holiday\", \"day\", \"personal\", \"raises\", \"store\", \"flex\", \"weekends\", \"weeks\", \"card\", \"vacations\", \"items\", \"level\", \"open\", \"gift\", \"cards\", \"year\", \"christmas\", \"friday\", \"generous\", \"bonus\", \"plenty\", \"rate\", \"leave\", \"shift\", \"start\", \"employee\", \"healthcare\", \"awful\", \"satelite\", \"band\", \"concessions\", \"retire\", \"mission\", \"strategy\", \"produced\", \"concession\", \"mealsall\", \"teen\", \"bargained\", \"efforts\", \"continually\", \"external\", \"logo\", \"coorporate\", \"facing\", \"succeed\", \"stripped\", \"infinite\", \"mentoring\", \"complexity\", \"satellite\", \"communications\", \"drinkssoda\", \"specifications\", \"technological\", \"empresa\", \"comprometida\", \"team\", \"opportunities\", \"training\", \"advancement\", \"culture\", \"compensation\", \"opportunity\", \"experience\", \"learning\", \"career\", \"growth\", \"support\", \"education\", \"development\", \"strong\", \"advance\", \"professional\", \"oriented\", \"community\", \"diversity\", \"building\", \"corporate\", \"resources\", \"facility\", \"educational\", \"global\", \"change\", \"exposure\", \"mobility\", \"communication\", \"industry\", \"position\", \"travel\", \"family\", \"activities\", \"leadership\", \"flexibility\", \"management\", \"great\", \"company\", \"envirioment\", \"niceclean\", \"inputs\", \"weve\", \"chatted\", \"manfacture\", \"mayores\", \"familiar\", \"sustain\", \"coowers\", \"honesty\", \"scoop\", \"possessed\", \"discover\", \"pd\", \"diagnostic\", \"industrial\", \"icon\", \"body\", \"cyclable\", \"achievable\", \"coworks\", \"inbetween\", \"bigname\", \"rolling\", \"couls\", \"plesant\", \"ham\", \"cheep\", \"couldnt\", \"friendly\", \"nice\", \"coworkers\", \"atmosphere\", \"gym\", \"cafeteria\", \"workers\", \"staff\", \"managers\", \"location\", \"onsite\", \"site\", \"wonderful\", \"awesome\", \"manager\", \"helpful\", \"cafe\", \"workplace\", \"financial\", \"caring\", \"supportive\", \"wide\", \"worker\", \"variety\", \"feeling\", \"players\", \"amenities\", \"house\", \"micro\", \"managing\", \"interaction\", \"incentive\", \"supervisors\", \"management\", \"comfortable\", \"great\", \"large\", \"worked\", \"meet\", \"people\", \"amazing\", \"scheduling\", \"included\", \"competive\", \"brks\", \"mangement\", \"hockey\", \"depot\", \"design\", \"feet\", \"degree\", \"massages\", \"reduced\", \"businesses\", \"testing\", \"administration\", \"offsite\", \"research\", \"orca\", \"ssei\", \"competent\", \"chosen\", \"launches\", \"existing\", \"shares\", \"parental\", \"physical\", \"running\", \"ice\", \"guess\", \"socials\", \"series\", \"employees\", \"discounts\", \"events\", \"service\", \"tuition\", \"reimbursement\", \"cable\", \"services\", \"customer\", \"close\", \"products\", \"phone\", \"recognition\", \"internet\", \"brand\", \"meetings\", \"provide\", \"product\", \"kroger\", \"assistance\", \"special\", \"parttime\", \"exciting\", \"happy\", \"cell\", \"discounted\", \"pros\", \"vehicle\", \"companies\", \"treated\", \"college\", \"car\", \"company\", \"rewards\", \"part\", \"employee\", \"healthcare\", \"great\", \"benefits\", \"drink\", \"parking\", \"mckesson\", \"payroll\", \"catering\", \"electronics\", \"tee\", \"int\", \"picnics\", \"throught\", \"beneits\", \"urgent\", \"payed\", \"designed\", \"chocolate\", \"bbqs\", \"wonderfully\", \"incredibly\", \"golden\", \"exclusive\", \"brings\", \"wk\", \"trading\", \"giveaways\", \"walking\", \"pool\", \"metlife\", \"police\", \"matter\", \"vip\", \"flexible\", \"schedule\", \"food\", \"hours\", \"room\", \"drinks\", \"coffee\", \"perks\", \"snacks\", \"schedules\", \"times\", \"meals\", \"set\", \"breakfast\", \"parties\", \"soda\", \"school\", \"fruit\", \"area\", \"needed\", \"prizes\", \"facilities\", \"cheap\", \"water\", \"dinner\", \"equipment\", \"machines\", \"hot\", \"fountain\", \"lots\", \"workout\", \"free\", \"campus\", \"flexibility\", \"laidback\", \"ease\", \"expect\", \"promotion\", \"ot\", \"women\", \"advancment\", \"sharing\", \"profit\", \"standing\", \"pretty\", \"standard\", \"lake\", \"consistant\", \"delivering\", \"engagement\", \"greatbreak\", \"familiarize\", \"affable\", \"excelente\", \"notices\", \"fcg\", \"peon\", \"oasis\", \"bolsas\", \"desarrollo\", \"relavent\", \"king\", \"goodpay\", \"ppr\", \"good\", \"decent\", \"relaxed\", \"back\", \"fair\", \"starting\", \"code\", \"average\", \"consistent\", \"success\", \"retail\", \"resume\", \"dress\", \"leaders\", \"laid\", \"setting\", \"adequate\", \"increases\", \"allowance\", \"core\", \"heavy\", \"national\", \"pay\", \"business\", \"values\", \"casual\", \"amount\", \"hired\", \"individuals\", \"union\", \"benefits\", \"wages\", \"benifits\", \"clean\", \"weekly\", \"funded\", \"install\", \"firms\", \"guest\", \"merch\", \"passed\", \"healthdental\", \"engage\", \"employers\", \"espp\", \"purchased\", \"preferred\", \"refrigerator\", \"ping\", \"sti\", \"investments\", \"woking\", \"grounds\", \"packages\", \"brilliant\", \"troubleshooting\", \"successful\", \"offers\", \"demanding\", \"fabulous\", \"wellness\", \"maternity\", \"improving\", \"cheaper\", \"review\", \"health\", \"excellent\", \"fast\", \"salary\", \"care\", \"paced\", \"package\", \"options\", \"dental\", \"insurance\", \"benefit\", \"programs\", \"pace\", \"vision\", \"stock\", \"grow\", \"retirement\", \"potential\", \"center\", \"low\", \"pension\", \"plan\", \"plans\", \"medical\", \"stress\", \"purchase\", \"stocks\", \"including\", \"field\", \"competitive\", \"match\", \"fitness\", \"move\", \"benefits\", \"program\", \"amazing\", \"pay\", \"high\", \"benifits\", \"awa\", \"journal\", \"fam\", \"immense\", \"plants\", \"difrent\", \"multidepartmental\", \"snaks\", \"handshake\", \"pressured\", \"siminizing\", \"workshoes\", \"cordial\", \"muito\", \"fundraising\", \"bu\", \"drawn\", \"fil\", \"conmin\", \"onset\", \"cowokers\", \"timetable\", \"vacfor\", \"passing\", \"healthcarevision\", \"benefitseven\", \"answered\", \"crown\", \"closedpaid\", \"ad\", \"lunch\", \"lunches\", \"breaks\", \"hour\", \"break\", \"bonuses\", \"long\", \"incentives\", \"minute\", \"provided\", \"membership\", \"shifts\", \"commission\", \"hr\", \"awards\", \"min\", \"short\", \"quarterly\", \"based\", \"games\", \"multiple\", \"tools\", \"allowed\", \"check\", \"pot\", \"fridays\", \"catered\", \"end\", \"tickets\", \"dinners\", \"occasional\", \"month\", \"knowledge\", \"give\", \"monthly\", \"free\", \"access\"], \"Total\": [5415.0, 5129.0, 9034.0, 5589.0, 7119.0, 5452.0, 2497.0, 3018.0, 2220.0, 2253.0, 2080.0, 1892.0, 1724.0, 1647.0, 1540.0, 1437.0, 1383.0, 1265.0, 1256.0, 1591.0, 1214.0, 1206.0, 1143.0, 1131.0, 1112.0, 1103.0, 1112.0, 1300.0, 1052.0, 1066.0, 1.0824601714657889, 7.5772212002605235, 1.0824601714657889, 1.0824601714657889, 7.5772212002605235, 1.0824601714657889, 1.0824601714657889, 20.566743257849993, 1.0824601714657889, 10.82460171465789, 3.247380514397367, 1.0824601714657889, 3.247380514397367, 3.247380514397367, 1.0824601714657889, 3.247380514397367, 3.247380514397367, 9.742141543192101, 5.412300857328945, 1.0824601714657889, 14.071982229055259, 5.412300857328945, 11.90706188612368, 1.0824601714657889, 1.0824601714657889, 28.143964458110517, 9.742141543192101, 1.0824601714657889, 1.0824601714657889, 19.484283086384202, 1030.4969438205494, 744.7325979684629, 593.1881739632523, 592.1057137917866, 470.87017458761824, 357.21185658371036, 303.0888480104209, 290.09932595283146, 274.9448835523104, 237.0587775510078, 227.3166360078157, 203.50251223556833, 201.33759189263677, 162.36902571986835, 150.46196383374468, 143.96720280494995, 140.71982229055257, 127.73030023296312, 126.64784006149732, 120.15307903270259, 120.15307903270259, 117.98815868977101, 113.65831800390785, 110.41093748951049, 110.41093748951049, 108.24601714657891, 108.24601714657891, 106.08109680364733, 102.83371628924996, 97.42141543192102, 265.217533909753, 127.73623902916516, 3018.0964425833545, 142.89150780544142, 119.05375432004378, 115.80637380564642, 880.703418410497, 227.80361729638412, 147.39274720540897, 13.968587344452903, 7.5215470316284865, 30.086188126513946, 7.5215470316284865, 7.5215470316284865, 27.937174688905806, 78.43899047269707, 7.5215470316284865, 7.5215470316284865, 39.756748595750565, 7.5215470316284865, 13.968587344452903, 7.5215470316284865, 13.968587344452903, 74.14096359748079, 15.043094063256973, 7.5215470316284865, 7.5215470316284865, 366.4067911121877, 354.58721720534294, 571.6375744037649, 1143.2751488075298, 702.7273940978614, 55.87434937781161, 186.9641690719081, 1.0745067188040696, 1.0745067188040696, 1.0745067188040696, 1.0745067188040696, 1.0745067188040696, 5415.48901372058, 2253.881688499635, 1066.9406163297845, 1112.1757050220967, 210.60331688559762, 203.08176985396912, 162.2505145394145, 140.7603801633331, 95.63109797356219, 90.25856437954184, 80.58800391030522, 77.364483753893, 75.21547031628486, 64.47040312824417, 53.72533594020347, 51.57632250259533, 51.57632250259533, 47.27829562737906, 44.054775470966845, 40.83125531455464, 40.83125531455464, 119.19569863146025, 120.356008657175, 78.4647586451103, 288.51860656713706, 139.59770558578305, 80.43890959872229, 880.703418410497, 98.43926922664248, 208.73570722596975, 1.0847152287848807, 3.2541456863546423, 2.1694304575697614, 1.0847152287848807, 1.0847152287848807, 4.338860915139523, 8.677721830279046, 3.2541456863546423, 1.0847152287848807, 2.1694304575697614, 42.30389392261034, 6.508291372709285, 32.54145686354642, 1.0847152287848807, 1.0847152287848807, 1.0847152287848807, 1.0847152287848807, 1.0847152287848807, 2.1694304575697614, 4.338860915139523, 1.0847152287848807, 2.1694304575697614, 9.762437059063926, 5.423576143924403, 3.2541456863546423, 1.0847152287848807, 1.0847152287848807, 3.2541456863546423, 1.0847152287848807, 3.2541456863546423, 2497.0144566627955, 1647.6824325242337, 1014.2087389138635, 721.3333720846266, 706.1394054289765, 498.96900524104507, 421.95422399731854, 489.209243758207, 361.21017118536525, 276.60238334014457, 269.00937673865036, 260.3316549083714, 656.2083465816467, 225.62076758725516, 220.19719144333078, 274.4275093527892, 169.21557569044137, 151.8601320298833, 144.26712542838914, 142.09769497081936, 141.0129797420345, 126.91168176783103, 124.74225131026127, 116.06452947998223, 113.89509902241247, 111.72566856484272, 189.81495652737328, 99.79380104820902, 99.79380104820902, 93.28550967549974, 406.79115593429606, 225.59821701406426, 130.17117860663728, 181.15090287601146, 206.0773506896662, 131.23421209361373, 1021.7406691237163, 597.7171178465194, 1.0655956302727743, 1.0655956302727743, 1.0655956302727743, 2.1311912605455485, 4.262382521091097, 14.918338823818841, 8.524765042182194, 1.0655956302727743, 1.0655956302727743, 1.0655956302727743, 1.0655956302727743, 1.0655956302727743, 18.115125714637163, 3.196786890818323, 6.393573781636646, 3.196786890818323, 1.0655956302727743, 3.196786890818323, 27.70548638709213, 1.0655956302727743, 4.262382521091097, 22.377508235728257, 1.0655956302727743, 3.196786890818323, 8.524765042182194, 1.0655956302727743, 1.0655956302727743, 5.3279781513638715, 4.262382521091097, 1.0655956302727743, 1265.927608764056, 1112.4818380047764, 1103.9570729625943, 855.6732911090378, 821.5742309403089, 726.7362198460321, 686.2435858956667, 499.7643505979311, 659.5671049010887, 415.594020932693, 474.1581795445862, 297.30118084610405, 254.67735563519307, 215.25031731510043, 180.08566151609887, 170.4953008436439, 255.76207086397795, 152.38017512900672, 143.85541008682455, 141.72421882627899, 286.62692942449695, 121.47790185109628, 112.95313680891407, 95.90360672454969, 82.05086353100363, 76.72288537963975, 68.19812033745755, 67.13252470718479, 67.13252470718479, 63.93573781636646, 128.95987460040078, 106.56847411580874, 223.69857417539956, 398.93427729077183, 188.5555412016431, 148.11380018221885, 380.41877773777423, 1591.8108117768352, 7119.499165375191, 1300.491511985037, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 5.282240354165585, 1.0564480708331168, 1.0564480708331168, 3.1693442124993507, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 3.1693442124993507, 1.0564480708331168, 3.1693442124993507, 1.0564480708331168, 1.0564480708331168, 3.1693442124993507, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 1.0564480708331168, 4.225792283332467, 1214.9152814580846, 1206.4636968914194, 1540.3985452732556, 552.52234104572, 483.8532164415675, 455.32911852907336, 527.1904109738915, 428.91791675824544, 356.0229998707604, 257.77332928328053, 252.49108892911494, 251.4346408582818, 217.62830259162206, 381.42340082708745, 209.17671802495715, 165.86234712079937, 159.52365869580066, 116.20928779164285, 61.27398810832078, 61.27398810832078, 179.65094656663075, 48.59661125832338, 44.37081897499091, 114.1224037506093, 42.25792283332468, 41.20147476249156, 39.088578620825324, 38.0321305499922, 36.97568247915909, 33.806338266659736, 86.65475390894825, 79.25642894064991, 83.49551489175813, 1591.8108117768352, 75.04440326690992, 7119.499165375191, 132.47220246426235, 201.39330343321745, 297.8344036826212, 3018.0964425833545, 313.1920047604855, 138.79723619010363, 20.660425295202888, 13.04868966012814, 3.262172415032035, 13.04868966012814, 3.262172415032035, 13.04868966012814, 14.13608046513882, 6.52434483006407, 13.04868966012814, 13.04868966012814, 35.88389656535239, 20.660425295202888, 14.13608046513882, 3.262172415032035, 13.04868966012814, 13.04868966012814, 3.262172415032035, 3.262172415032035, 14.13608046513882, 3.262172415032035, 13.04868966012814, 3.262172415032035, 13.04868966012814, 6.52434483006407, 50.019977030491205, 13.04868966012814, 41.320850590405776, 3.262172415032035, 6.52434483006407, 3.262172415032035, 1052.5942992503367, 1039.5456095902084, 382.7615633637588, 434.9573301669285, 308.8189886230327, 284.89639091279776, 270.7603104476589, 253.36205756748805, 419.67332242124684, 247.9251035424347, 465.36046617761446, 227.26467824723179, 227.26467824723179, 166.37079316663377, 155.496885116527, 129.39950579627072, 110.91386211108919, 189.17505733768047, 104.38951728102512, 101.12734486599308, 101.12734486599308, 91.34082762089697, 79.37952876577953, 75.02996554573681, 73.94257474072613, 146.76002553830446, 64.15605749563002, 60.89388508059799, 58.719103470576634, 55.456931055544594, 102.20185158479715, 81.52336764162332, 1300.491511985037, 167.38841238815982, 260.91809989674346, 1021.7406691237163, 597.7171178465194, 7119.499165375191, 9034.70392798648, 46.40868305696858, 167.28711334488673, 3.237815096997808, 3.237815096997808, 12.951260387991232, 3.237815096997808, 3.237815096997808, 3.237815096997808, 44.25013965897004, 3.237815096997808, 3.237815096997808, 3.237815096997808, 26.98179247498173, 3.237815096997808, 26.98179247498173, 22.664705678984657, 3.237815096997808, 6.475630193995616, 3.237815096997808, 3.237815096997808, 6.475630193995616, 6.475630193995616, 3.237815096997808, 26.98179247498173, 22.664705678984657, 31.29887927097881, 3.237815096997808, 3.237815096997808, 12.951260387991232, 3.237815096997808, 1724.6666450404418, 1033.9422876413, 1131.085867819903, 2080.9318682643166, 467.3246456666836, 446.8184833856975, 473.795510880484, 306.51316251579254, 265.5008379538202, 261.18375115782317, 251.47030586682976, 195.34817751886774, 194.26890581986848, 192.11036242186995, 181.31764543187725, 150.01876616089842, 138.1467774719065, 127.35406048191378, 127.35406048191378, 120.87843028791816, 102.53081140493059, 94.97590951193571, 91.73809441493789, 86.34173591994154, 80.9453774249452, 78.78683402694666, 76.62829062894814, 72.31120383295105, 72.31120383295105, 884.4831025677939, 72.31120383295105, 5452.784633627672, 160.90933883874584, 380.41877773777423, 7.347603668115073, 7.347603668115073, 7.347603668115073, 32.53938767308104, 75.57535201489789, 7.347603668115073, 14.695207336230146, 132.25686602607132, 104.96576668735818, 9.446919001862236, 94.46919001862236, 14.695207336230146, 7.347603668115073, 7.347603668115073, 7.347603668115073, 26.241441671839546, 1.049657666873582, 1.049657666873582, 1.049657666873582, 2.099315333747164, 1.049657666873582, 1.049657666873582, 1.049657666873582, 1.049657666873582, 1.049657666873582, 1.049657666873582, 1.049657666873582, 2.099315333747164, 1.049657666873582, 1.049657666873582, 5129.677018011194, 1040.3063756521149, 248.76886704903893, 149.05138869604863, 227.7916516749665, 123.85960469108267, 103.9161090204846, 86.07192868363371, 62.97946001241491, 60.88014467866775, 60.88014467866775, 54.582198677426256, 153.3092474277943, 34.6387030068282, 97.6341009826423, 27.291099338713128, 25.191784004965967, 23.092468671218803, 19.943495670598058, 17.844180336850894, 16.79452266997731, 16.79452266997731, 5589.1657189659745, 200.62538540968913, 62.986250416374446, 145.17579570365064, 87.3319317219751, 35.73805877756276, 35.73935619901228, 206.68310136161458, 9034.70392798648, 152.58580901083994, 272.8326233443528, 208.30924957758646, 238.16461012605845, 3.2319622697516164, 3.2319622697516164, 3.2319622697516164, 7.541245296087105, 3.2319622697516164, 10.773207565838721, 3.2319622697516164, 5.3866037829193605, 16.159811348758083, 10.773207565838721, 3.2319622697516164, 3.2319622697516164, 3.2319622697516164, 48.47943404627425, 3.2319622697516164, 6.463924539503233, 3.2319622697516164, 7.541245296087105, 72.18049069111943, 15.08249059217421, 3.2319622697516164, 20.469094375093572, 51.71139631602586, 16.159811348758083, 5.3866037829193605, 45.24747177652264, 32.31962269751617, 7.541245296087105, 10.773207565838721, 12.927849079006466, 1437.1458892828855, 1383.279851453692, 624.8460388186459, 623.7687180620621, 572.0573217460361, 400.7633214492005, 343.6653213502553, 305.9590948698197, 259.63430233671323, 819.9150404823367, 211.15486829043897, 191.76309467192925, 172.37132105341954, 164.83007575733245, 323.21838339732966, 160.520792730997, 150.8249059217421, 148.67026440857438, 138.97437759931952, 116.3506417110582, 105.57743414521948, 239.17548679138346, 81.87637750037429, 356.6188675036713, 75.41245296087105, 68.94852842136783, 64.63924539503233, 56.020679342361355, 53.866037829193615, 370.5786420003934, 113.10695431499548, 103.41997859427194, 161.5643450342232, 9034.70392798648, 187.73797034364893, 313.1920047604855, 5589.1657189659745, 225.66884019933906, 272.8326233443528, 1.0883989676678434, 1.0883989676678434, 2.1767979353356868, 1.0883989676678434, 7.618792773674904, 2.1767979353356868, 1.0883989676678434, 1.0883989676678434, 1.0883989676678434, 2.1767979353356868, 1.0883989676678434, 1.0883989676678434, 1.0883989676678434, 1.0883989676678434, 2.1767979353356868, 1.0883989676678434, 1.0883989676678434, 1.0883989676678434, 1.0883989676678434, 1.0883989676678434, 4.3535958706713735, 1.0883989676678434, 1.0883989676678434, 2.1767979353356868, 1.0883989676678434, 1.0883989676678434, 2.1767979353356868, 1.0883989676678434, 1.0883989676678434, 1.0883989676678434, 2220.3338940424005, 1892.6285590323332, 1256.0124086886913, 907.7247390349814, 675.8957589217308, 578.9895094984985, 359.17165933038837, 323.2544933973495, 277.54173675530006, 263.369746838223, 166.52504205318004, 161.08304721484083, 133.87307302314474, 120.81228541113062, 115.3702905727914, 190.43786844503788, 107.7514977991165, 107.7514977991165, 103.39790192844514, 102.3095029607773, 101.22110399310945, 96.86750812243807, 96.86750812243807, 84.89511947809179, 74.01112980141336, 68.56913496307413, 60.95034218939923, 59.86194322173139, 59.86194322173139, 59.86194322173139, 171.91774647784615, 184.9366111539531, 181.66298857677342, 100.09396372464735, 109.92627940913786, 5452.784633627672, 117.38038152176182], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2968, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2979, 2.2855, 2.2893, 2.0732, 2.2749, 2.2889, 2.2886, 1.4713, 1.8007, 2.0475, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2987, 2.2876, 2.2939, 2.2931, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2989, 2.2721, 2.2625, 2.2708, 2.1867, 2.1942, 2.2174, 1.7235, 2.0155, 1.573, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.2989, 2.2989, 2.3004, 2.3004, 2.2982, 2.3004, 2.3004, 2.3004, 2.3004, 2.2905, 2.3004, 2.3004, 2.2965, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.3004, 2.2947, 2.3004, 2.3004, 2.3004, 2.2733, 2.2512, 2.2836, 2.245, 2.2125, 2.2754, 0.4763, 0.8561, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.2942, 2.298, 2.2962, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.2964, 2.3006, 2.3006, 2.3006, 2.2932, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.3006, 2.2921, 2.2905, 2.2671, 2.2418, 2.2664, 2.264, 2.0505, 0.6614, -0.3972, 0.2109, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.2972, 2.3007, 2.3007, 2.3007, 2.2987, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.295, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.2886, 2.3007, 2.3007, 2.2912, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.3007, 2.2881, 2.287, 2.2746, 2.0764, 2.2422, 1.7688, 2.1606, 2.0808, 1.9673, 0.6976, 1.3795, 1.7533, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.2993, 2.3018, 2.3018, 2.3018, 2.3018, 2.2968, 2.3018, 2.2949, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.2962, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.3018, 2.2947, 2.3018, 2.3018, 2.3018, 2.3018, 2.2913, 2.2888, 2.1688, 2.2557, 2.2286, 2.1259, 2.0328, 1.2382, 0.6019, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.3037, 2.305, 2.304, 2.295, 2.305, 2.305, 2.3027, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.305, 2.2581, 2.305, 1.6978, 1.9733, 0.7967, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.2995, 2.3057, 2.3057, 2.301, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.2915, 2.3057, 2.2947, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.3057, 2.243, 2.2785, 2.2888, 2.2045, 2.2282, 2.2437, 2.2436, 1.9788, 1.2514, 1.9612, 1.7289, 1.5149, 1.0709, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.294, 2.3074, 2.3074, 2.3074, 2.3074, 2.3006, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.2983, 2.3074, 2.2921, 2.3074, 2.3074, 2.3074, 2.3074, 2.3074, 2.2869, 2.2979, 2.2969, 2.2242, 1.5466, 2.0668, 1.7998, -0.6977, 1.6632, 1.4825, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3035, 2.3075, 2.3075, 2.3075, 2.3056, 2.3075, 2.3075, 2.3075, 2.3034, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3019, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.3075, 2.2886, 2.2841, 2.2838, 2.2969, 2.2875, 1.5202, 2.1911], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -9.8025, -7.8566, -9.8025, -9.8025, -7.8566, -9.8025, -9.8025, -6.8581, -9.8025, -7.4999, -8.7039, -9.8025, -8.7039, -8.7039, -9.8025, -8.7039, -8.7039, -7.6053, -8.1931, -9.8025, -7.2376, -8.1931, -7.4046, -9.8025, -9.8025, -6.5444, -7.6053, -9.8025, -9.8025, -6.9121, -2.945, -3.2687, -3.4962, -3.4981, -3.7272, -4.0034, -4.1677, -4.2115, -4.2652, -4.4134, -4.4554, -4.5661, -4.5768, -4.7919, -4.868, -4.9122, -4.935, -5.0318, -5.0403, -5.093, -5.093, -5.1112, -5.1485, -5.1775, -5.1775, -5.1973, -5.1973, -5.2175, -5.2486, -5.3027, -4.3136, -5.0403, -2.0941, -4.9427, -5.1112, -5.1391, -3.9276, -4.9505, -5.1391, -7.2439, -7.8629, -6.4766, -7.8629, -7.8629, -6.5508, -5.5184, -7.8629, -7.8629, -6.1979, -7.8629, -7.2439, -7.8629, -7.2439, -5.5747, -7.1698, -7.8629, -7.8629, -3.977, -4.0098, -3.5322, -2.8391, -3.3257, -5.8576, -4.6498, -9.8088, -9.8088, -9.8088, -9.8088, -9.8088, -1.2839, -2.1716, -2.9132, -2.8725, -4.5307, -4.5671, -4.7916, -4.9336, -5.3202, -5.378, -5.4914, -5.5322, -5.5604, -5.7145, -5.8968, -5.9376, -5.9376, -6.0247, -6.0953, -6.1713, -6.1713, -5.1267, -5.1267, -5.5462, -4.3282, -5.0467, -5.5747, -3.6754, -5.5747, -5.2656, -9.7979, -8.6993, -9.1048, -9.7979, -9.7979, -8.4116, -7.7185, -8.6993, -9.7979, -9.1048, -6.1343, -8.0061, -6.3967, -9.7979, -9.7979, -9.7979, -9.7979, -9.7979, -9.1048, -8.4116, -9.7979, -9.1048, -7.6007, -8.1885, -8.6993, -9.7979, -9.7979, -8.6993, -9.7979, -8.6993, -2.0564, -2.4721, -2.9574, -3.2996, -3.3209, -3.6667, -3.8343, -3.6887, -3.9898, -4.2566, -4.2845, -4.3173, -3.4026, -4.4604, -4.4847, -4.2685, -4.748, -4.8563, -4.9076, -4.9227, -4.9304, -5.0357, -5.053, -5.1251, -5.1439, -5.1632, -4.6388, -5.2761, -5.2761, -5.3436, -3.898, -4.5096, -5.0272, -4.7353, -4.6388, -5.0272, -4.774, -4.9304, -9.8155, -9.8155, -9.8155, -9.1223, -8.4292, -7.1764, -7.736, -9.8155, -9.8155, -9.8155, -9.8155, -9.8155, -6.9823, -8.7169, -8.0237, -8.7169, -9.8155, -8.7169, -6.5574, -9.8155, -8.4292, -6.771, -9.8155, -8.7169, -7.736, -9.8155, -9.8155, -8.206, -8.4292, -9.8155, -2.7354, -2.8647, -2.8724, -3.1271, -3.1678, -3.2904, -3.3478, -3.6649, -3.3939, -3.8519, -3.7219, -4.1843, -4.339, -4.5072, -4.6856, -4.7403, -4.339, -4.8526, -4.9102, -4.9251, -4.2282, -5.0793, -5.152, -5.3157, -5.4717, -5.5388, -5.6566, -5.6723, -5.6723, -5.7211, -5.028, -5.2204, -4.5023, -3.949, -4.6738, -4.9176, -4.1879, -4.1456, -3.7062, -4.7982, -9.824, -9.824, -9.824, -9.824, -9.824, -9.824, -9.824, -8.2146, -9.824, -9.824, -8.7254, -9.824, -9.824, -9.824, -9.824, -9.824, -8.7254, -9.824, -8.7254, -9.824, -9.824, -8.7254, -9.824, -9.824, -9.824, -9.824, -9.824, -9.824, -9.824, -8.4377, -2.7765, -2.7835, -2.5426, -3.5644, -3.6971, -3.7579, -3.6134, -3.8177, -4.0039, -4.3268, -4.3475, -4.3517, -4.4961, -3.9407, -4.5357, -4.7678, -4.8067, -5.1235, -5.7636, -5.7636, -4.7, -5.9954, -6.0863, -5.1512, -6.1351, -6.1604, -6.2131, -6.2405, -6.2687, -6.3583, -5.4296, -5.5199, -5.4802, -2.7306, -5.6193, -1.5403, -5.1327, -4.7936, -4.5157, -3.4696, -5.0533, -5.4933, -6.8496, -7.3091, -8.6954, -7.3091, -8.6954, -7.3091, -7.2291, -8.0022, -7.3091, -7.3091, -6.2975, -6.8496, -7.2291, -8.6954, -7.3091, -7.3091, -8.6954, -8.6954, -7.2291, -8.6954, -7.3091, -8.6954, -7.3091, -8.0022, -5.9654, -7.3091, -6.1564, -8.6954, -8.0022, -8.6954, -2.9188, -2.9312, -3.9304, -3.805, -4.145, -4.2257, -4.2766, -4.343, -3.8434, -4.3647, -3.7419, -4.4517, -4.4517, -4.7636, -4.8312, -5.0149, -5.169, -4.6407, -5.2297, -5.2614, -5.2614, -5.3632, -5.5035, -5.5599, -5.5745, -4.8962, -5.7165, -5.7687, -5.805, -5.8622, -5.2614, -5.4899, -2.8403, -4.8036, -4.3868, -3.1245, -3.7538, -2.0709, -2.4689, -6.0371, -4.7549, -8.6997, -8.6997, -7.3134, -8.6997, -8.6997, -8.6997, -6.0848, -8.6997, -8.6997, -8.6997, -6.5795, -8.6997, -6.5795, -6.7538, -8.6997, -8.0066, -8.6997, -8.6997, -8.0066, -8.0066, -8.6997, -6.5795, -6.7538, -6.4311, -8.6997, -8.6997, -7.3134, -8.6997, -2.4231, -2.9335, -2.8447, -2.244, -3.7276, -3.7725, -3.7161, -4.1494, -4.293, -4.3094, -4.3473, -4.5999, -4.6054, -4.6166, -4.6744, -4.8639, -4.9463, -5.0277, -5.0277, -5.0799, -5.2445, -5.321, -5.3557, -5.4163, -5.4809, -5.5079, -5.5357, -5.5937, -5.5937, -3.1365, -5.5937, -1.8779, -5.1255, -5.4416, -7.8796, -7.8796, -7.8796, -6.3915, -5.5488, -7.8796, -7.1864, -4.9892, -5.2203, -7.6282, -5.3257, -7.1864, -7.8796, -7.8796, -7.8796, -6.6066, -9.8255, -9.8255, -9.8255, -9.1323, -9.8255, -9.8255, -9.8255, -9.8255, -9.8255, -9.8255, -9.8255, -9.1323, -9.8255, -9.8255, -1.3311, -2.9328, -4.3574, -4.8696, -4.4502, -5.0548, -5.2304, -5.4188, -5.7311, -5.765, -5.765, -5.8742, -4.8557, -6.329, -5.3037, -6.5674, -6.6474, -6.7344, -6.881, -6.9923, -7.0529, -7.0529, -1.3081, -4.5997, -5.7479, -4.9972, -5.4817, -6.3597, -6.3597, -4.8696, -1.8194, -5.1907, -4.8419, -5.3257, -5.6358, -8.6992, -8.6992, -8.6992, -7.8519, -8.6992, -7.4952, -8.6992, -8.1884, -7.0897, -7.4952, -8.6992, -8.6992, -8.6992, -5.9911, -8.6992, -8.006, -8.6992, -7.8519, -5.5931, -7.1587, -8.6992, -6.8534, -5.9266, -7.0897, -8.1884, -6.0601, -6.3966, -7.8519, -7.4952, -7.3129, -2.6019, -2.6401, -3.4348, -3.4365, -3.523, -3.8789, -4.0326, -4.1488, -4.313, -3.1764, -4.5197, -4.616, -4.7226, -4.7674, -4.1007, -4.7938, -4.8562, -4.8705, -4.938, -5.1157, -5.2128, -4.4042, -5.4671, -4.0109, -5.5493, -5.6389, -5.7034, -5.8465, -5.8858, -3.9777, -5.1534, -5.2439, -4.8705, -1.5242, -4.8778, -4.633, -4.2487, -5.0973, -5.0883, -9.7875, -9.7875, -9.0943, -9.7875, -7.8415, -9.0943, -9.7875, -9.7875, -9.7875, -9.0943, -9.7875, -9.7875, -9.7875, -9.7875, -9.0943, -9.7875, -9.7875, -9.7875, -9.7875, -9.7875, -8.4012, -9.7875, -9.7875, -9.0943, -9.7875, -9.7875, -9.0943, -9.7875, -9.7875, -9.7875, -2.1668, -2.3304, -2.7365, -3.0612, -3.3561, -3.5127, -3.9884, -4.0937, -4.2462, -4.3027, -4.757, -4.7902, -4.9753, -5.0779, -5.124, -4.6284, -5.1923, -5.1923, -5.2336, -5.2442, -5.2549, -5.2988, -5.2988, -5.4308, -5.568, -5.6443, -5.7621, -5.7801, -5.7801, -5.7801, -4.744, -4.6755, -4.6937, -5.2766, -5.1923, -2.0555, -5.2231]}, \"token.table\": {\"Topic\": [2, 2, 10, 3, 5, 2, 4, 5, 10, 8, 6, 4, 1, 4, 8, 8, 8, 10, 2, 1, 3, 5, 9, 5, 3, 8, 10, 2, 7, 6, 5, 1, 8, 10, 10, 5, 7, 4, 8, 2, 2, 4, 4, 10, 3, 7, 1, 9, 3, 6, 8, 9, 10, 7, 8, 9, 1, 5, 5, 8, 2, 3, 10, 8, 10, 1, 1, 6, 10, 7, 10, 9, 7, 6, 10, 4, 5, 1, 4, 7, 8, 6, 1, 6, 5, 5, 3, 5, 7, 5, 6, 3, 3, 9, 4, 9, 5, 2, 8, 10, 7, 6, 9, 1, 2, 9, 4, 3, 5, 7, 9, 10, 5, 7, 2, 6, 3, 5, 6, 8, 6, 10, 2, 8, 2, 7, 2, 2, 6, 2, 6, 4, 5, 10, 4, 4, 4, 6, 4, 6, 10, 4, 6, 2, 9, 6, 2, 4, 4, 4, 4, 2, 10, 8, 8, 2, 8, 4, 1, 4, 4, 5, 10, 8, 4, 5, 5, 10, 1, 5, 8, 5, 10, 4, 4, 6, 8, 1, 5, 1, 3, 9, 2, 3, 3, 4, 8, 6, 2, 8, 9, 9, 6, 8, 6, 7, 4, 5, 1, 10, 7, 10, 1, 3, 6, 8, 6, 3, 5, 2, 5, 6, 7, 4, 10, 7, 8, 7, 7, 4, 1, 8, 1, 1, 4, 4, 4, 7, 3, 6, 6, 9, 4, 10, 9, 8, 2, 2, 1, 1, 5, 2, 2, 5, 7, 9, 1, 6, 1, 3, 8, 9, 6, 7, 6, 8, 4, 4, 4, 9, 7, 4, 4, 4, 8, 10, 5, 8, 3, 4, 9, 2, 8, 5, 6, 9, 10, 5, 9, 2, 9, 3, 2, 4, 7, 2, 7, 7, 10, 3, 7, 7, 10, 1, 10, 3, 10, 2, 1, 5, 1, 7, 3, 2, 3, 9, 10, 3, 10, 2, 3, 3, 8, 10, 7, 4, 1, 10, 7, 8, 8, 4, 5, 6, 8, 3, 9, 9, 4, 8, 6, 9, 5, 5, 10, 3, 6, 2, 1, 9, 3, 6, 10, 9, 2, 3, 8, 5, 1, 6, 1, 9, 3, 3, 2, 8, 6, 3, 3, 6, 2, 4, 1, 5, 2, 7, 10, 1, 3, 7, 9, 5, 10, 6, 5, 10, 9, 5, 5, 7, 10, 6, 9, 3, 8, 7, 3, 4, 8, 5, 4, 10, 4, 2, 5, 9, 3, 9, 7, 2, 1, 5, 1, 6, 9, 3, 1, 9, 2, 10, 8, 8, 9, 10, 6, 4, 8, 8, 8, 1, 5, 6, 8, 4, 5, 9, 1, 1, 2, 4, 5, 1, 3, 10, 3, 2, 2, 2, 5, 2, 4, 10, 1, 4, 7, 1, 9, 3, 1, 10, 2, 10, 7, 1, 1, 4, 5, 5, 5, 5, 2, 5, 6, 2, 6, 4, 9, 9, 7, 5, 7, 7, 4, 1, 9, 1, 5, 1, 6, 1, 4, 10, 4, 9, 3, 7, 5, 1, 5, 10, 3, 10, 4, 4, 1, 1, 4, 10, 6, 10, 2, 9, 10, 10, 10, 1, 8, 7, 5, 5, 3, 8, 8, 3, 4, 10, 9, 2, 5, 6, 10, 5, 3, 4, 4, 9, 6, 1, 4, 8, 3, 1, 9, 9, 9, 9, 3, 6, 7, 2, 3, 6, 7, 6, 9, 10, 3, 6, 8, 9, 7, 1, 7, 5, 9, 8, 1, 5, 7, 3, 1, 6, 1, 6, 7, 9, 2, 1, 9, 9, 10, 5, 2, 1, 3, 5, 3, 7, 7, 2, 4, 2, 5, 10, 9, 8, 9, 10, 8, 3, 7, 4, 5, 6, 2, 4, 6, 7, 3, 4, 8, 5, 9, 9, 1, 8, 6, 6, 4, 10, 2, 3, 9, 9, 10, 3, 3, 6, 3, 6, 1, 6, 9, 6, 1, 8, 8, 2, 2, 6, 4, 1, 8, 8, 4, 9, 9, 2, 2, 3, 6, 5, 7, 1, 6, 2, 9, 1, 3, 9, 1, 10, 4, 4, 1, 7, 7, 3, 5, 6, 8, 7, 5, 1, 1, 6, 6, 10, 6, 7, 8, 6, 8, 3, 8, 10, 10, 10, 3, 3, 2, 10, 5, 1, 2, 3, 7, 10, 6, 7, 2, 6, 4, 6, 1, 5, 8, 8, 3, 7, 8, 2, 8, 9, 9, 10, 9, 3, 7, 4, 9, 4, 4, 4, 8, 9, 1, 2, 5, 4, 5, 7, 10, 5, 4, 2, 5, 4, 1, 7, 4, 2, 6, 7, 10, 3, 7, 10, 10, 1, 3, 7, 4, 3, 4, 8, 6, 9, 6, 2, 6, 8, 3, 1, 2, 7, 3, 3, 3, 10, 5, 8, 1, 1, 5, 6, 7, 9, 1, 1, 1, 3, 8, 7, 3, 7, 2, 3, 3, 3, 7, 8, 10, 3, 9, 5, 5, 7, 9, 8, 5, 7, 2, 8, 3, 2, 5, 5, 5, 7, 1, 2, 2, 7, 5, 10, 1, 2, 3], \"Freq\": [0.9988897828259325, 0.11075104571533409, 0.8860083657226727, 0.9219009500956483, 0.9465680591488025, 0.9306596064033961, 0.9652328371796162, 0.03182086276416317, 0.9187807317961175, 0.9923870415478252, 0.9196325694423909, 0.9970949296479549, 0.9948847129079915, 1.0003818149921904, 1.0207409570206203, 0.9526915598859123, 1.0028332209325392, 1.0013677638676786, 1.0022488068959652, 0.9797643131502367, 0.020994949567505073, 0.39911619102663276, 0.6034636808322688, 0.9977339001838729, 0.0801539581453986, 0.9274958013967552, 0.9187807317961175, 0.9971352925750673, 0.9972198728444621, 0.9987407474589407, 1.0008645061363055, 0.9238215191288495, 0.9991643189047372, 0.9187807317961175, 0.9967904165712596, 0.9936464285572608, 0.005243516773389239, 0.938442286727487, 0.9996552283309924, 1.0082145736036792, 0.999759332818686, 0.938442286727487, 0.938442286727487, 0.9961517407894747, 0.9219009500956483, 1.014793676377904, 0.9238215191288495, 0.9992665653806951, 0.0015495803859861637, 0.1827398012330826, 0.3484342182203174, 0.4673091706881131, 0.9187807317961175, 0.9265507479972168, 0.5607833774588338, 0.4398300999677127, 1.0021114783770568, 0.9465680591488025, 0.9465680591488024, 0.9526915598859123, 0.002458263866880915, 0.9734724912848425, 0.02458263866880915, 0.0017271470097379948, 0.9982909716285611, 1.0016170154765418, 0.9238215191288494, 0.9968045333116824, 1.0001542265606689, 0.9994255259295821, 0.9999901205683913, 0.9945307048812607, 0.9265507479972168, 0.9196325694423909, 0.9187807317961175, 0.9943238779839578, 0.006977711424448827, 0.009968828201455561, 0.004984414100727781, 0.009968828201455561, 0.9719607496419171, 1.016435997804748, 0.9983232545424663, 1.0008852462605942, 1.0029860229391283, 0.9992771854123089, 0.9219009500956483, 0.2796605860465093, 0.7146881643410793, 0.012266421627673668, 0.9813137302138935, 0.9993124802563517, 1.0024554020457535, 0.9998997971988871, 0.998570670166621, 0.002406194385943665, 0.9955284760013267, 0.09643480810381362, 0.9023542758285418, 1.0008147257064852, 1.0037633103303183, 1.0007766196873078, 1.0001843678030662, 1.0162036710417344, 0.48386546481317183, 0.5174006950477481, 0.9970949296479549, 1.0371385688576042, 0.9465680591488025, 1.0028549272440463, 1.0210515236780944, 1.0012354128547434, 0.9465680591488025, 1.0006748078369943, 1.0636109787467385, 0.9196325694423909, 1.0020662501039657, 0.23522719274042392, 0.31203607200260314, 0.451252165665303, 1.0003020930776882, 0.9187807317961175, 1.0636109787467385, 1.0008072952336857, 0.002110615185318318, 0.9983209826555645, 1.0051123749156678, 0.9685876986347693, 0.025489149964072876, 0.00978455854266297, 0.98824041280896, 0.05330177635996687, 0.946106530389412, 1.0009481143144694, 1.0010051058426526, 1.0557475725684229, 1.0010051058426526, 1.0047837332796492, 0.12379934702861206, 0.8750537696805002, 0.0007689400436559755, 1.0003629654705029, 0.9903735363225747, 0.02158786042502554, 0.9795491667855338, 0.9962686168959235, 1.0636109787467385, 0.938442286727487, 0.938442286727487, 0.938442286727487, 0.938442286727487, 0.9927035801636226, 0.9187807317961175, 0.9526915598859124, 1.000326137880208, 0.9199527985791522, 0.07459076745236369, 0.9384422867274869, 0.9911489198634506, 0.00839956711748687, 0.938442286727487, 0.9465680591488025, 0.9187807317961175, 1.0087322398792011, 0.996065935912508, 0.9465680591488025, 0.9465680591488025, 0.9187807317961175, 0.002596730574872381, 0.9964953581072761, 0.0006491826437180952, 0.9465680591488024, 0.9187807317961175, 1.0005182356549862, 0.00238280573621082, 0.9960127977361228, 0.00238280573621082, 1.0003590577776058, 0.9465680591488025, 0.996929696901636, 0.9905390618482872, 0.00914343749398419, 0.001416150964401292, 0.9983864299029109, 0.9219009500956482, 0.0057675317006866435, 0.9939379630849982, 0.9962686168959235, 1.0636109787467385, 0.9526915598859124, 0.9901105684151217, 1.0014085105858335, 0.9962686168959235, 0.9526915598859123, 0.9903735363225747, 0.9265507479972168, 0.9988370873584637, 0.9465680591488025, 0.9238215191288495, 0.9187807317961175, 1.000674807836994, 1.0023062528684918, 0.001386321552141747, 0.998151517542058, 0.9948213041288543, 0.006813844548827769, 1.0004371048327265, 0.9219009500956483, 0.9465680591488025, 0.9025936312583073, 0.05730753214338458, 0.02865376607169229, 0.007163441517923073, 1.0019459001150612, 0.9187807317961175, 0.013045527478320976, 0.9849373246132337, 0.9911938234388832, 1.000406242402792, 0.938442286727487, 1.0264683545876103, 0.9526915598859124, 1.0002757138153748, 0.995674303949982, 1.0012668749602893, 0.999380097553947, 0.993644774182045, 0.9265507479972168, 0.16148911850744893, 0.8387646943083863, 1.0003854293624355, 0.9901105684151217, 0.938442286727487, 1.0023062528684918, 0.9282286578891766, 0.9907992222813489, 1.0022488068959652, 0.9971352925750673, 1.003006220768465, 0.9238215191288494, 0.9465680591488025, 1.0001916459622706, 0.9889605170375211, 0.011091975292031417, 1.002705603996988, 1.0210515236780944, 0.9238215191288495, 1.000622937773965, 1.0019910322859058, 0.9219009500956483, 0.9526915598859123, 0.9997976899226879, 0.9952188080266969, 0.9265507479972168, 0.9196325694423909, 0.9526915598859124, 1.0004715210314359, 0.9980259239800257, 0.9384422867274869, 0.9282286578891766, 1.0002536484060862, 1.0010051058426528, 0.9384422867274869, 0.00438997650988057, 0.9965246677428895, 0.9187807317961175, 0.9465680591488024, 0.9526915598859123, 0.057653606895343205, 0.942511138810828, 1.0002463985874748, 1.006118493409077, 0.9526915598859123, 0.9938964621062425, 1.072904664349456, 1.0024869505203107, 0.9187807317961175, 0.9955284760013267, 0.9282286578891766, 0.009669311612634452, 0.986269784488714, 0.9987260292702858, 1.0082145736036792, 0.7780898770565822, 0.22080928943497602, 0.0011596443902659821, 0.9990336422141435, 0.9990399775553771, 0.0008841061748277673, 0.9219009500956483, 0.9956963262059643, 0.5448592232448817, 0.45518027334022093, 0.7802283503117973, 0.22389161356773313, 1.0020662501039657, 1.006283658633843, 1.0636109787467385, 0.9238215191288494, 1.000069732057213, 1.000227810184619, 0.9972198728444621, 1.0014375026529199, 0.9944471858230584, 0.006293969530525686, 0.9282286578891766, 0.9187807317961175, 0.9219009500956483, 0.9969748366298294, 1.0022488068959652, 0.9969393995220382, 1.0009210315324182, 0.009990612448428375, 0.9890706323944091, 1.0006748078369943, 1.0036118899724513, 0.9942362556251788, 0.007828631934056526, 0.9265507479972168, 1.000062963416151, 0.9526915598859123, 0.06742047282404652, 0.5874008694795053, 0.34524900458647156, 0.9526915598859123, 0.9219009500956484, 1.0608327518733447, 1.002985328323204, 0.9954483975228287, 0.0042180016844187655, 0.9196325694423909, 1.0608327518733447, 1.0003033638166385, 0.9465680591488025, 0.9187807317961175, 0.9219009500956483, 0.9996006189591204, 1.001883555873044, 0.9238215191288495, 0.9998984867966617, 0.23589754382139963, 0.7645757271374443, 0.9187807317961175, 0.9282286578891766, 0.9971352925750673, 0.9219009500956483, 1.0122347823787816, 1.0008299224121096, 0.9878683212896179, 0.011311469327743717, 0.4741460979082631, 0.5273213612250777, 0.9219009500956483, 0.9219009500956483, 0.05596274863299652, 0.9513667267609409, 0.9196325694423909, 0.9987260292702856, 0.99752816657977, 0.0020441150954503486, 0.9953693614675764, 0.004686296428755068, 0.9948847129079915, 0.9465680591488024, 0.9306596064033961, 0.9956963262059643, 1.000303242770833, 0.9987259666257831, 0.00961107872151614, 0.9899411083161624, 0.000480553936075807, 0.9991551735459583, 1.0015537706966686, 0.9922351407141586, 0.9465680591488025, 0.9187807317961175, 1.0608327518733447, 0.9465680591488025, 0.984147293065768, 0.012617272988022666, 0.9992127150509964, 1.016435997804748, 0.9996308623421901, 1.0243343889951648, 0.9959957216989083, 0.9265507479972168, 0.0279803585277688, 0.0279803585277688, 0.9513321899441393, 0.9465680591488024, 0.9925567964192344, 0.007754349972025269, 0.938442286727487, 0.9306596064033961, 0.9465680591488025, 0.9282286578891766, 0.013416024169441945, 0.9866875957344121, 0.9265507479972168, 0.994113670476355, 0.011540047774536889, 0.9924441086101724, 1.0027806233278964, 0.9977712844930516, 0.9282286578891766, 1.0006959030952765, 0.9985473573410131, 0.000970405595083589, 1.0038575529744498, 0.9187807317961175, 0.9526915598859123, 0.01100939721221624, 0.01100939721221624, 0.9743316532811372, 0.9962686168959235, 0.010242323019677143, 0.9935053329086829, 0.9526915598859124, 0.9526915598859124, 0.12832880924272524, 0.8681066507596119, 0.9962686168959235, 1.0104304423032404, 0.9654738439232027, 0.020254696026360895, 0.013503130684240597, 0.9998214612875299, 0.9986070706773753, 1.0636109787467385, 0.9930756023653218, 0.006064583831238606, 0.027601297706047013, 0.9439643815468078, 0.02208103816483761, 1.0020662501039657, 1.0003879255375956, 1.0636109787467385, 1.004132733224717, 1.0008793412311108, 0.994403415061163, 0.9384422867274869, 0.9995220688327459, 0.9996827752616929, 0.0452241539537315, 0.9542296484237346, 0.9987259666257831, 0.9969863362513378, 0.9219009500956483, 1.055796021861542, 0.9998496198957749, 0.004226925543219244, 0.9959693311210344, 1.004850811208249, 1.0024446271398153, 0.006910368944988766, 0.1941185458183208, 0.7990899361841555, 0.9991551735459581, 0.9999353977951742, 1.0057285628456027, 0.9306596064033961, 0.9465680591488025, 0.9962686168959235, 0.9987566507743765, 0.9962686168959235, 0.008841189350878156, 0.9902132072983534, 0.9901105684151217, 1.0037633103303183, 0.9465680591488025, 0.9265507479972168, 0.9982176566820844, 0.938442286727487, 0.014020570574406095, 0.9842440543233079, 0.2820359198311832, 0.7151625110005002, 0.9994069161484825, 0.9969126172946927, 0.9930368788940778, 0.008635103294731111, 1.0028521713068734, 0.9831300146668912, 0.9282286578891766, 0.9219009500956483, 0.9265507479972168, 1.000657662528734, 1.0264683545876103, 0.005251056463534243, 0.9924496716079719, 0.9219009500956482, 1.001651150742434, 1.005473878636593, 0.9980259239800257, 1.0002004636237543, 0.9238215191288495, 0.021629032645516272, 0.9787137272096113, 0.0181940115753044, 0.9824766250664376, 0.08046329774831376, 0.9222331818845193, 0.9187807317961175, 0.9187807317961175, 0.9978156334559984, 0.9238215191288495, 1.0122347823787816, 1.0010057188184218, 0.999615656158893, 0.9465680591488025, 0.9219009500956482, 0.9526915598859123, 0.9526915598859123, 0.0058167351567097415, 0.011633470313419483, 0.9830282414839463, 1.0055810460466081, 0.8942230903917959, 0.10744541008583594, 0.9962686168959235, 0.9187807317961175, 0.9980550247091975, 0.9994440206644412, 0.9995668801158673, 0.9996450445575403, 1.0001336947679156, 0.9196325694423909, 0.9238215191288494, 0.9975050879900561, 1.005618868768463, 1.0000621176037576, 0.9238215191288495, 0.9978458072308649, 1.0005905693912898, 1.00097385051372, 0.9974994532540407, 1.0001927358509732, 1.072904664349456, 0.9982837091324852, 0.0038326202758480273, 0.06515454468941646, 0.9274941067552226, 0.9982481273065252, 0.9962686168959236, 1.0210515236780944, 0.9187807317961175, 0.008230208641677249, 0.0030415988458372444, 0.939138373047041, 0.049560169429230395, 1.0006748078369943, 0.9238215191288495, 0.9265507479972168, 0.9465680591488025, 1.0040024258801297, 0.9526915598859123, 0.798847898291909, 0.2011201469362044, 1.001588308574456, 1.0016808400077717, 0.9238215191288495, 0.9988353744661375, 0.9238215191288495, 0.9996006189591206, 0.9943471441921351, 0.9901105684151217, 1.0011641220400171, 0.008362060957126698, 0.9909042234195138, 1.0015098677225327, 1.0500351220527058, 0.995110010900023, 1.0022488068959652, 0.04875925060752691, 0.9530217164198441, 0.9465680591488025, 0.9219009500956482, 0.9265507479972168, 0.9904507995832318, 0.009383638156564884, 0.9852820064393127, 0.99959735502587, 0.9465680591488025, 0.9998496198957748, 1.0022178987354151, 0.9526915598859123, 0.9282286578891766, 0.9187807317961175, 0.995033406991953, 1.075551108444923, 1.0045760741443508, 0.938442286727487, 0.0052861091418356715, 0.9937885186651062, 0.002148871837381926, 0.002148871837381926, 0.9927787888704498, 0.002148871837381926, 0.00390988388787261, 0.9970203914075154, 1.000326137880208, 0.21306291916750328, 0.7883328009197622, 1.0012354062624826, 0.9962781088644453, 1.014155531491455, 0.9975675329544579, 1.0007766196873078, 0.0037969433164024647, 0.9947991488974457, 1.0636109787467385, 1.0001084857078757, 1.0007465217867684, 0.9282286578891766, 1.0023062528684918, 0.9991044779361705, 0.9833205888593946, 0.01536438420092804, 0.9219009500956483, 0.9988353744661375, 0.9238215191288494, 1.00323553030079, 0.9282286578891766, 1.000363672866723, 0.9962781088644453, 0.9526915598859123, 1.0009291072219078, 1.001702324449457, 0.9980987083166858, 0.9962686168959235, 1.0004148905679815, 0.9751449368582299, 1.007654534494715, 1.0019687095351837, 0.938442286727487, 1.001160909580469, 1.0055810460466081, 1.0051123749156678, 0.029870645934590833, 0.011948258373836333, 0.9558606699069067, 0.9465680591488025, 0.9993053101956126, 0.9238215191288495, 0.9962686168959235, 0.9638073021382525, 0.033234734556491466, 0.9977272406591574, 0.9219009500956483, 1.0003707815593197, 0.6101746831313654, 0.3906873870409462, 0.938442286727487, 0.9384422867274869, 1.0078052935951083, 1.0000558177757015, 0.9992964678812958, 0.3962614927336828, 0.5763803530671749, 0.007204754413339686, 0.014409508826679372, 0.9989375251844992, 0.9465680591488025, 0.9996576139827101, 0.9238215191288495, 0.9196325694423909, 0.9977990250984824, 0.002299076094696964, 0.9985709874202785, 0.9986158061747781, 0.9893335429584474, 0.9962686168959235, 0.9980578246423842, 0.9171313556171288, 0.009705093710234166, 0.07278820282675626, 0.9994844447241548, 1.0023062528684918, 0.9219009500956483, 0.9999651434505219, 1.0636109787467385, 0.9187807317961175, 0.9982713564972665, 0.9997068582001477, 0.9984560015718554, 0.9928164077953137, 1.0018800771026817, 0.9187807317961175, 1.072904664349456, 0.9998749079106657, 0.9952887457369655, 0.9987407474589407, 0.938442286727487, 0.9196325694423909, 0.9977272406591573, 1.0001913728444243, 1.0207409570206203, 0.9526915598859124, 0.9753554195813919, 0.022859892646438874, 1.0011335036089248, 0.9731894802568255, 0.0251686934549179, 0.9282286578891766, 0.9931365803701746, 0.006187766855888939, 1.005581046046608, 0.9947982279321931, 0.003643949552865176, 1.0557475725684229, 0.9945307048812607, 0.938442286727487, 0.9995243290588618, 1.0106301549372936, 1.0019687095351837, 0.9770827977780806, 0.9238215191288495, 0.023953382437281318, 0.9701119887098933, 0.9989869503873248, 0.9852439042638301, 0.00556634974160356, 0.00556634974160356, 0.9465680591488025, 1.0000571843409076, 0.7517325207852313, 0.24380514187629124, 0.9384422867274869, 0.9997520549476588, 0.9265507479972168, 0.938442286727487, 1.004132733224717, 0.9903735363225747, 0.9265507479972168, 1.0023062528684918, 0.999994210420866, 0.998129775739491, 0.9187807317961175, 1.0013677638676786, 0.9977272406591573, 0.9219009500956482, 0.9265507479972168, 1.0000388846980168, 0.00447030117955026, 0.9655850547828562, 0.02682180707730156, 0.9917606141045392, 0.9282286578891766, 1.0005861406961225, 0.9971352925750673, 0.2806228453990667, 0.720910413180361, 1.014091045105213, 1.021065889563465, 0.9306596064033961, 0.9265507479972168, 0.9219009500956483, 0.9997941854513234, 0.99990795356528, 0.9187807317961175, 0.015876480873038782, 0.9843418141284046, 1.055796021861542, 0.00876252135544999, 0.9901649131658489, 1.0017426202854616, 0.9265507479972168, 1.001030905566759, 0.9238215191288495, 1.0001003601578369, 0.006553689405867084, 0.28180864445228465, 0.7077984558336451, 1.014793676377904, 0.9219009500956483, 0.9960420540970081, 1.0022488068959652, 0.9994181471006878, 1.0009210315324182, 0.4282752166495782, 0.27711925783207997, 0.28971558773353817, 0.004198776633819394, 0.9981483970960402, 0.9945307048812605, 0.9465680591488025, 1.0083007586585069, 0.9265507479972168, 0.9282286578891766, 0.9526915598859124, 1.0017079460895095, 0.9265507479972168, 0.9997250453806096, 0.00018465553110096224, 0.9219009500956483, 0.19861633588658079, 0.8043961603406522, 0.9916427286320787, 0.9977419714981302, 0.0018968478545591829, 0.43715056845680483, 0.5620507308730348, 1.0006340128998923, 0.9956963262059643, 0.9981990441932826, 0.9187807317961175, 0.9992355206903881, 0.005268288749710772, 0.995706573695336], \"Term\": [\"ability\", \"access\", \"access\", \"acess\", \"achievable\", \"actitivies\", \"activities\", \"activities\", \"ad\", \"adequate\", \"administration\", \"advance\", \"advanced\", \"advancement\", \"advancment\", \"affable\", \"allowance\", \"allowed\", \"allowing\", \"alot\", \"alot\", \"amazing\", \"amazing\", \"amenities\", \"amount\", \"amount\", \"answered\", \"approachable\", \"area\", \"assistance\", \"atmosphere\", \"attached\", \"average\", \"awa\", \"awards\", \"awesome\", \"awesome\", \"awful\", \"back\", \"bad\", \"balance\", \"band\", \"bargained\", \"based\", \"bases\", \"bbqs\", \"begining\", \"benefit\", \"benefits\", \"benefits\", \"benefits\", \"benefits\", \"benefitseven\", \"beneits\", \"benifits\", \"benifits\", \"big\", \"bigname\", \"body\", \"bolsas\", \"bonus\", \"bonus\", \"bonus\", \"bonuses\", \"bonuses\", \"boss\", \"bottom\", \"brand\", \"break\", \"breakfast\", \"breaks\", \"brilliant\", \"brings\", \"brks\", \"bu\", \"building\", \"building\", \"business\", \"business\", \"business\", \"business\", \"businesses\", \"busy\", \"cable\", \"cafe\", \"cafeteria\", \"calloff\", \"campus\", \"campus\", \"car\", \"car\", \"card\", \"cards\", \"care\", \"career\", \"career\", \"caring\", \"casual\", \"casual\", \"catered\", \"catering\", \"cell\", \"center\", \"certification\", \"challenging\", \"challenging\", \"change\", \"charity\", \"chatted\", \"cheap\", \"cheaper\", \"check\", \"cheep\", \"chocolate\", \"chose\", \"chosen\", \"christmas\", \"clean\", \"clean\", \"clean\", \"close\", \"closedpaid\", \"closing\", \"code\", \"coffee\", \"coffee\", \"collaborative\", \"colleagues\", \"colleagues\", \"college\", \"college\", \"comfortable\", \"comfortable\", \"commission\", \"communication\", \"communications\", \"community\", \"companies\", \"company\", \"company\", \"company\", \"compensation\", \"competent\", \"competitive\", \"competitive\", \"competive\", \"completed\", \"complexity\", \"comprometida\", \"concession\", \"concessions\", \"conditions\", \"conmin\", \"consistant\", \"consistent\", \"constant\", \"constant\", \"continually\", \"cool\", \"cool\", \"coorporate\", \"coowers\", \"cordial\", \"core\", \"corporate\", \"couldnt\", \"couls\", \"cowokers\", \"coworkers\", \"coworkers\", \"coworkers\", \"coworks\", \"crown\", \"culture\", \"customer\", \"customer\", \"customer\", \"customers\", \"cyclable\", \"daily\", \"day\", \"day\", \"days\", \"days\", \"decades\", \"decent\", \"decent\", \"degree\", \"deliver\", \"delivering\", \"demanding\", \"dental\", \"depot\", \"desarrollo\", \"design\", \"designed\", \"development\", \"diagnostic\", \"dicount\", \"difrent\", \"dinner\", \"dinners\", \"discount\", \"discount\", \"discounted\", \"discounted\", \"discounts\", \"discouts\", \"discover\", \"diverse\", \"diverse\", \"diverse\", \"diverse\", \"diversity\", \"drawn\", \"dress\", \"dress\", \"drink\", \"drinks\", \"drinkssoda\", \"drugs\", \"ease\", \"easy\", \"edge\", \"education\", \"educational\", \"efforts\", \"electronics\", \"employee\", \"employee\", \"employees\", \"employers\", \"empresa\", \"end\", \"engage\", \"engagement\", \"engaging\", \"enjoyable\", \"enjoyed\", \"entrylevel\", \"envirioment\", \"enviroment\", \"environment\", \"environment\", \"equipment\", \"espp\", \"evaluations\", \"events\", \"everyday\", \"exceeds\", \"excelente\", \"excellent\", \"exciting\", \"exclusive\", \"existing\", \"expect\", \"experience\", \"exposure\", \"external\", \"fabulous\", \"facilities\", \"facility\", \"facing\", \"fair\", \"fair\", \"fam\", \"familiar\", \"familiarize\", \"family\", \"family\", \"fast\", \"fastpaced\", \"fcg\", \"feeling\", \"feet\", \"field\", \"fil\", \"financial\", \"firms\", \"fitness\", \"fitness\", \"flex\", \"flexable\", \"flexibility\", \"flexibility\", \"flexible\", \"flexible\", \"food\", \"food\", \"foremen\", \"fountain\", \"free\", \"free\", \"freedom\", \"freedom\", \"friday\", \"fridays\", \"friend\", \"friendliness\", \"friendly\", \"friends\", \"fruit\", \"full\", \"fun\", \"fun\", \"funded\", \"fundraising\", \"futher\", \"games\", \"generally\", \"generous\", \"gift\", \"give\", \"give\", \"giveaways\", \"global\", \"goals\", \"goals\", \"golden\", \"good\", \"goodpay\", \"great\", \"great\", \"great\", \"greatbreak\", \"grill\", \"grounds\", \"grow\", \"growth\", \"growth\", \"guess\", \"guest\", \"gym\", \"ham\", \"handshake\", \"happen\", \"happy\", \"hard\", \"healt\", \"health\", \"healthcare\", \"healthcare\", \"healthcarevision\", \"healthdental\", \"healthy\", \"hearing\", \"heavy\", \"helpful\", \"helping\", \"helping\", \"high\", \"high\", \"hightech\", \"hippa\", \"hired\", \"hired\", \"hockey\", \"holiday\", \"holidays\", \"holidays\", \"home\", \"home\", \"homes\", \"honesty\", \"horizontal\", \"hot\", \"hour\", \"hourly\", \"hours\", \"hours\", \"hours\", \"house\", \"hr\", \"ice\", \"icon\", \"immense\", \"improving\", \"inbetween\", \"incentive\", \"incentive\", \"incentives\", \"included\", \"including\", \"increased\", \"increases\", \"incredibly\", \"individuals\", \"individuals\", \"individuals\", \"industrial\", \"industry\", \"industry\", \"infinite\", \"infotainment\", \"inputs\", \"install\", \"insurance\", \"insurance\", \"int\", \"intelligent\", \"interaction\", \"interaction\", \"interesting\", \"internet\", \"investments\", \"items\", \"job\", \"job\", \"jobs\", \"journal\", \"king\", \"knowledge\", \"knowledge\", \"knowledge\", \"kroger\", \"laid\", \"laid\", \"laidback\", \"lake\", \"large\", \"large\", \"launches\", \"leaders\", \"leadership\", \"leadership\", \"leadership\", \"learn\", \"learned\", \"learner\", \"learning\", \"learning\", \"leave\", \"leave\", \"leave\", \"level\", \"life\", \"lifestyle\", \"listen\", \"location\", \"locations\", \"logo\", \"long\", \"lot\", \"lots\", \"lots\", \"love\", \"low\", \"lowstress\", \"loyal\", \"lunch\", \"lunches\", \"lunches\", \"machines\", \"make\", \"management\", \"management\", \"management\", \"manager\", \"managers\", \"managing\", \"managmen\", \"manfacture\", \"mangement\", \"market\", \"massages\", \"match\", \"match\", \"maternity\", \"matter\", \"mayores\", \"mckesson\", \"meals\", \"mealsall\", \"medical\", \"medical\", \"meet\", \"meet\", \"meeting\", \"meetings\", \"members\", \"members\", \"membership\", \"mentoring\", \"merch\", \"merchandiseing\", \"metlife\", \"micro\", \"micromanagement\", \"min\", \"min\", \"mini\", \"minute\", \"mission\", \"mobility\", \"money\", \"monotony\", \"month\", \"month\", \"monthly\", \"monthly\", \"move\", \"move\", \"muito\", \"multidepartmental\", \"multiple\", \"multitask\", \"national\", \"needed\", \"nice\", \"niceclean\", \"noon\", \"notices\", \"oasis\", \"occasional\", \"occasional\", \"occasional\", \"offers\", \"office\", \"office\", \"offsite\", \"onset\", \"onsite\", \"open\", \"opportunities\", \"opportunity\", \"options\", \"orca\", \"ordering\", \"oriented\", \"ot\", \"overtime\", \"oxygen\", \"pace\", \"paced\", \"package\", \"packages\", \"paid\", \"parental\", \"parking\", \"part\", \"part\", \"part\", \"parties\", \"parttime\", \"passed\", \"passing\", \"pay\", \"pay\", \"pay\", \"pay\", \"payed\", \"payfull\", \"payroll\", \"pd\", \"pension\", \"peon\", \"people\", \"people\", \"perks\", \"personal\", \"philanthropist\", \"phone\", \"photo\", \"physical\", \"picnics\", \"ping\", \"place\", \"plan\", \"plan\", \"plans\", \"plants\", \"players\", \"pleasant\", \"plenty\", \"plenty\", \"plesant\", \"pods\", \"police\", \"pool\", \"position\", \"position\", \"positive\", \"possessed\", \"pot\", \"potential\", \"ppr\", \"preferred\", \"pressured\", \"pretty\", \"pricing\", \"prizes\", \"produced\", \"product\", \"product\", \"products\", \"products\", \"products\", \"products\", \"professional\", \"professional\", \"profit\", \"program\", \"program\", \"programs\", \"projects\", \"promotion\", \"pros\", \"provide\", \"provided\", \"provided\", \"proximity\", \"pto\", \"purchase\", \"purchased\", \"quarterly\", \"raises\", \"rate\", \"rate\", \"realy\", \"recognition\", \"reduce\", \"reduced\", \"refrigerator\", \"reimbursement\", \"relationships\", \"relavent\", \"relaxed\", \"remote\", \"remotely\", \"research\", \"resources\", \"responsibilities\", \"resume\", \"retail\", \"retire\", \"retirement\", \"review\", \"rewarding\", \"rewards\", \"rewards\", \"rewards\", \"rolling\", \"room\", \"round\", \"running\", \"safe\", \"safe\", \"safety\", \"saftey\", \"salary\", \"sales\", \"sales\", \"satelite\", \"satellite\", \"satisfied\", \"schedule\", \"schedules\", \"scheduling\", \"scheduling\", \"scheduling\", \"scheduling\", \"school\", \"scoop\", \"security\", \"semiregular\", \"series\", \"service\", \"service\", \"services\", \"set\", \"setting\", \"shares\", \"sharing\", \"shift\", \"shift\", \"shift\", \"shifts\", \"short\", \"showings\", \"sick\", \"significant\", \"siminizing\", \"site\", \"skills\", \"smart\", \"snack\", \"snacks\", \"snaks\", \"socials\", \"soda\", \"solid\", \"special\", \"specifications\", \"ssei\", \"stable\", \"staff\", \"standard\", \"standing\", \"start\", \"start\", \"starting\", \"steady\", \"steady\", \"sti\", \"stock\", \"stock\", \"stocks\", \"store\", \"store\", \"strategy\", \"stress\", \"stripped\", \"strong\", \"succeed\", \"success\", \"successful\", \"supervisorcant\", \"supervisors\", \"supervisors\", \"support\", \"supportive\", \"supportive\", \"supportive\", \"sustain\", \"team\", \"teams\", \"teams\", \"technological\", \"technology\", \"tee\", \"teen\", \"telecommute\", \"testing\", \"throught\", \"tickets\", \"time\", \"times\", \"timetable\", \"tools\", \"top\", \"topped\", \"trading\", \"training\", \"travel\", \"travel\", \"travel\", \"treated\", \"troubleshooting\", \"tuition\", \"type\", \"union\", \"union\", \"unpaid\", \"ups\", \"upword\", \"urgent\", \"utiilzed\", \"vacation\", \"vacations\", \"vacfor\", \"values\", \"values\", \"varied\", \"variety\", \"variety\", \"vehicle\", \"vip\", \"vision\", \"vp\", \"wage\", \"wages\", \"wages\", \"wages\", \"walking\", \"wallet\", \"water\", \"wealth\", \"week\", \"weekends\", \"weekly\", \"weekly\", \"weekly\", \"weekly\", \"weeks\", \"wellness\", \"weve\", \"wide\", \"wk\", \"woking\", \"women\", \"wonderful\", \"wonderfully\", \"work\", \"work\", \"workbalance\", \"worked\", \"worked\", \"worker\", \"workers\", \"workers\", \"working\", \"working\", \"worklife\", \"workout\", \"workplace\", \"workshoes\", \"world\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 4, 5, 8, 10, 6, 7, 1, 3, 9]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el42591122535964408501049198\", ldavis_el42591122535964408501049198_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el42591122535964408501049198\", ldavis_el42591122535964408501049198_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el42591122535964408501049198\", ldavis_el42591122535964408501049198_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1     -0.093720 -0.137420       1        1  10.047077\n",
       "3     -0.084768 -0.030520       2        1  10.036695\n",
       "4     -0.043812  0.040849       3        1  10.021786\n",
       "7     -0.040290 -0.211077       4        1  10.019655\n",
       "9      0.006931 -0.295722       5        1  10.018795\n",
       "5      0.199610 -0.101327       6        1  10.007428\n",
       "6     -0.249440  0.190179       7        1   9.975926\n",
       "0      0.279014  0.180607       8        1   9.968948\n",
       "2      0.277220  0.167663       9        1   9.952362\n",
       "8     -0.250745  0.196767      10        1   9.951329, topic_info=     Category         Freq           Term        Total  loglift  logprob\n",
       "term                                                                    \n",
       "20    Default  5415.000000           work  5415.000000  30.0000  30.0000\n",
       "13    Default  5129.000000           good  5129.000000  29.0000  29.0000\n",
       "4     Default  9034.000000       benefits  9034.000000  28.0000  28.0000\n",
       "19    Default  5589.000000            pay  5589.000000  27.0000  27.0000\n",
       "53    Default  7119.000000          great  7119.000000  26.0000  26.0000\n",
       "77    Default  5452.000000           free  5452.000000  25.0000  25.0000\n",
       "83    Default  2497.000000           time  2497.000000  24.0000  24.0000\n",
       "25    Default  3018.000000         people  3018.000000  23.0000  23.0000\n",
       "3     Default  2220.000000          lunch  2220.000000  22.0000  22.0000\n",
       "199   Default  2253.000000    environment  2253.000000  21.0000  21.0000\n",
       "14    Default  2080.000000          hours  2080.000000  20.0000  20.0000\n",
       "29    Default  1892.000000        lunches  1892.000000  19.0000  19.0000\n",
       "34    Default  1724.000000       flexible  1724.000000  18.0000  18.0000\n",
       "41    Default  1647.000000           paid  1647.000000  17.0000  17.0000\n",
       "0     Default  1540.000000      coworkers  1540.000000  16.0000  16.0000\n",
       "138   Default  1437.000000         health  1437.000000  15.0000  15.0000\n",
       "46    Default  1383.000000      excellent  1383.000000  14.0000  14.0000\n",
       "244   Default  1265.000000           team  1265.000000  13.0000  13.0000\n",
       "38    Default  1256.000000         breaks  1256.000000  12.0000  12.0000\n",
       "127   Default  1591.000000     management  1591.000000  11.0000  11.0000\n",
       "1     Default  1214.000000       friendly  1214.000000  10.0000  10.0000\n",
       "205   Default  1206.000000           nice  1206.000000   9.0000   9.0000\n",
       "107   Default  1143.000000        balance  1143.000000   8.0000   8.0000\n",
       "79    Default  1131.000000           food  1131.000000   7.0000   7.0000\n",
       "501   Default  1112.000000  opportunities  1112.000000   6.0000   6.0000\n",
       "403   Default  1103.000000       training  1103.000000   5.0000   5.0000\n",
       "27    Default  1112.000000            fun  1112.000000   4.0000   4.0000\n",
       "432   Default  1300.000000        company  1300.000000   3.0000   3.0000\n",
       "198   Default  1052.000000      employees  1052.000000   2.0000   2.0000\n",
       "485   Default  1066.000000           home  1066.000000   1.0000   1.0000\n",
       "...       ...          ...            ...          ...      ...      ...\n",
       "156   Topic10   323.254493     incentives   323.254493   2.3075  -4.0937\n",
       "39    Topic10   277.541737         minute   277.541737   2.3075  -4.2462\n",
       "954   Topic10   262.304151       provided   263.369747   2.3034  -4.3027\n",
       "1613  Topic10   166.525042     membership   166.525042   2.3075  -4.7570\n",
       "82    Topic10   161.083047         shifts   161.083047   2.3075  -4.7902\n",
       "2616  Topic10   133.873073     commission   133.873073   2.3075  -4.9753\n",
       "28    Topic10   120.812285             hr   120.812285   2.3075  -5.0779\n",
       "227   Topic10   115.370291         awards   115.370291   2.3075  -5.1240\n",
       "262   Topic10   189.381420            min   190.437868   2.3019  -4.6284\n",
       "139   Topic10   107.751498          short   107.751498   2.3075  -5.1923\n",
       "148   Topic10   107.751498      quarterly   107.751498   2.3075  -5.1923\n",
       "497   Topic10   103.397902          based   103.397902   2.3075  -5.2336\n",
       "1191  Topic10   102.309503          games   102.309503   2.3075  -5.2442\n",
       "500   Topic10   101.221104       multiple   101.221104   2.3075  -5.2549\n",
       "1959  Topic10    96.867508          tools    96.867508   2.3075  -5.2988\n",
       "17    Topic10    96.867508        allowed    96.867508   2.3075  -5.2988\n",
       "824   Topic10    84.895119          check    84.895119   2.3075  -5.4308\n",
       "175   Topic10    74.011130            pot    74.011130   2.3075  -5.5680\n",
       "274   Topic10    68.569135        fridays    68.569135   2.3075  -5.6443\n",
       "472   Topic10    60.950342        catered    60.950342   2.3075  -5.7621\n",
       "2026  Topic10    59.861943            end    59.861943   2.3075  -5.7801\n",
       "2289  Topic10    59.861943        tickets    59.861943   2.3075  -5.7801\n",
       "171   Topic10    59.861943        dinners    59.861943   2.3075  -5.7801\n",
       "173   Topic10   168.701840     occasional   171.917746   2.2886  -4.7440\n",
       "672   Topic10   180.674229          month   184.936611   2.2841  -4.6755\n",
       "1401  Topic10   177.409032      knowledge   181.662989   2.2838  -4.6937\n",
       "233   Topic10    99.044306           give   100.093964   2.2969  -5.2766\n",
       "848   Topic10   107.751498        monthly   109.926279   2.2875  -5.1923\n",
       "77    Topic10  2481.549646           free  5452.784634   1.5202  -2.0555\n",
       "959   Topic10   104.486301         access   117.380382   2.1911  -5.2231\n",
       "\n",
       "[703 rows x 6 columns], token_table=      Topic      Freq            Term\n",
       "term                                 \n",
       "69        2  0.998890         ability\n",
       "959       2  0.110751          access\n",
       "959      10  0.886008          access\n",
       "4377      3  0.921901           acess\n",
       "4060      5  0.946568      achievable\n",
       "4409      2  0.930660      actitivies\n",
       "437       4  0.965233      activities\n",
       "437       5  0.031821      activities\n",
       "4510     10  0.918781              ad\n",
       "556       8  0.992387        adequate\n",
       "6199      6  0.919633  administration\n",
       "329       4  0.997095         advance\n",
       "3101      1  0.994885        advanced\n",
       "226       4  1.000382     advancement\n",
       "1607      8  1.020741      advancment\n",
       "4360      8  0.952692         affable\n",
       "1501      8  1.002833       allowance\n",
       "17       10  1.001368         allowed\n",
       "3506      2  1.002249        allowing\n",
       "367       1  0.979764            alot\n",
       "367       3  0.020995            alot\n",
       "202       5  0.399116         amazing\n",
       "202       9  0.603464         amazing\n",
       "1234      5  0.997734       amenities\n",
       "91        3  0.080154          amount\n",
       "91        8  0.927496          amount\n",
       "4552     10  0.918781        answered\n",
       "2183      2  0.997135    approachable\n",
       "646       7  0.997220            area\n",
       "714       6  0.998741      assistance\n",
       "...     ...       ...             ...\n",
       "603       3  0.428275          weekly\n",
       "603       7  0.277119          weekly\n",
       "603       8  0.289716          weekly\n",
       "603      10  0.004199          weekly\n",
       "879       3  0.998148           weeks\n",
       "1457      9  0.994531        wellness\n",
       "4242      5  0.946568            weve\n",
       "966       5  1.008301            wide\n",
       "1442      7  0.926551              wk\n",
       "5347      9  0.928229          woking\n",
       "6919      8  0.952692           women\n",
       "269       5  1.001708       wonderful\n",
       "1733      7  0.926551     wonderfully\n",
       "20        2  0.999725            work\n",
       "20        8  0.000185            work\n",
       "4684      3  0.921901     workbalance\n",
       "323       2  0.198616          worked\n",
       "323       5  0.804396          worked\n",
       "585       5  0.991643          worker\n",
       "137       5  0.997742         workers\n",
       "137       7  0.001897         workers\n",
       "255       1  0.437151         working\n",
       "255       2  0.562051         working\n",
       "114       2  1.000634        worklife\n",
       "2008      7  0.995696         workout\n",
       "936       5  0.998199       workplace\n",
       "4130     10  0.918781       workshoes\n",
       "1237      1  0.999236           world\n",
       "417       2  0.005268            year\n",
       "417       3  0.995707            year\n",
       "\n",
       "[809 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 4, 5, 8, 10, 6, 7, 1, 3, 9])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pprint import pprint\n",
    "# %%time\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(optimal_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
